{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88419814",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-07-04T13:06:52.853491Z",
     "iopub.status.busy": "2022-07-04T13:06:52.852940Z",
     "iopub.status.idle": "2022-07-04T13:06:55.832504Z",
     "shell.execute_reply": "2022-07-04T13:06:55.831521Z"
    },
    "papermill": {
     "duration": 2.98833,
     "end_time": "2022-07-04T13:06:55.835090",
     "exception": false,
     "start_time": "2022-07-04T13:06:52.846760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import torch\n",
    "import random as r\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from time import time\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader as DL\n",
    "from torchvision import models, transforms\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74bab85e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T13:06:55.843757Z",
     "iopub.status.busy": "2022-07-04T13:06:55.842946Z",
     "iopub.status.idle": "2022-07-04T13:06:55.857194Z",
     "shell.execute_reply": "2022-07-04T13:06:55.856050Z"
    },
    "papermill": {
     "duration": 0.020803,
     "end_time": "2022-07-04T13:06:55.859507",
     "exception": false,
     "start_time": "2022-07-04T13:06:55.838704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "SIZE = 384\n",
    "\n",
    "def breaker(num: int=50, char: str=\"*\") -> None:\n",
    "    print(\"\\n\" + num*char + \"\\n\")\n",
    "\n",
    "\n",
    "def get_images(path: str, filenames: list, size: int=224) -> np.ndarray:\n",
    "    images = np.zeros((len(filenames), size, size, 3), dtype=np.uint8)\n",
    "    \n",
    "    i = 0\n",
    "    for filename in filenames:\n",
    "        image = cv2.imread(os.path.join(path, filename), cv2.IMREAD_COLOR)\n",
    "        if image is not None:\n",
    "            images[i] = cv2.resize(src=cv2.cvtColor(src=image, code=cv2.COLOR_BGR2RGB), dsize=(size, size), interpolation=cv2.INTER_AREA)\n",
    "        else:\n",
    "            images[i] = images[i-1]\n",
    "        i += 1\n",
    "    \n",
    "    return images\n",
    "\n",
    "\n",
    "def show_loss_graphs(L: list) -> None:\n",
    "    TL, VL = [], []\n",
    "    for i in range(len(L)):\n",
    "        TL.append(L[i][\"train\"])\n",
    "        VL.append(L[i][\"valid\"])\n",
    "    x_Axis = np.arange(1, len(TL) + 1)\n",
    "    plt.figure()\n",
    "    plt.plot(x_Axis, TL, \"r\", label=\"Train\")\n",
    "    plt.plot(x_Axis, VL, \"b\", label=\"Valid\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.title(\"Loss Graph\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def show_lr_graph(LR: list) -> None:\n",
    "    x_Axis = [i+1 for i in range(len(LR))]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(x_Axis, LR, \"rx\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "000939fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T13:06:55.867808Z",
     "iopub.status.busy": "2022-07-04T13:06:55.867132Z",
     "iopub.status.idle": "2022-07-04T13:06:55.936778Z",
     "shell.execute_reply": "2022-07-04T13:06:55.935758Z"
    },
    "papermill": {
     "duration": 0.076236,
     "end_time": "2022-07-04T13:06:55.939177",
     "exception": false,
     "start_time": "2022-07-04T13:06:55.862941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG(object):\n",
    "    def __init__(self, \n",
    "                 seed: int = 42,\n",
    "                 in_channels: int = 3,\n",
    "                 size: int = 224,\n",
    "                 n_splits: int = 5,\n",
    "                 batch_size: int = 16,\n",
    "                 epochs: int = 25,\n",
    "                 early_stopping: int = 5,\n",
    "                 lr: float = 1e-4,\n",
    "                 wd: float = 0.0,\n",
    "                 max_lr: float = 1e-3,\n",
    "                 pct_start: float = 0.2,\n",
    "                 steps_per_epoch: int = 100,\n",
    "                 div_factor: int = 1e3, \n",
    "                 final_div_factor: float = 1e3,\n",
    "                 ):\n",
    "        \n",
    "        self.seed = seed\n",
    "        self.in_channels = in_channels\n",
    "        self.size = size\n",
    "        self.n_splits = n_splits\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.early_stopping = early_stopping\n",
    "        self.lr = lr\n",
    "        self.wd = wd\n",
    "        self.max_lr = max_lr\n",
    "        self.pct_start = pct_start\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.div_factor = div_factor\n",
    "        self.final_div_factor = final_div_factor\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.42810, 0.42018, 0.41788],\n",
    "                                                     [0.28410, 0.28240, 0.28896]),\n",
    "                                ])\n",
    "        self.train_path = \"../input/clpd-analysis\"\n",
    "        self.save_path = \"saves\"\n",
    "        if not os.path.exists(self.save_path): os.makedirs(self.save_path)\n",
    "    \n",
    "cfg = CFG(seed=SEED, size=SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b73088",
   "metadata": {
    "papermill": {
     "duration": 0.003117,
     "end_time": "2022-07-04T13:06:55.945831",
     "exception": false,
     "start_time": "2022-07-04T13:06:55.942714",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Dataset Template**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8757e64f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T13:06:55.953845Z",
     "iopub.status.busy": "2022-07-04T13:06:55.952973Z",
     "iopub.status.idle": "2022-07-04T13:06:55.959333Z",
     "shell.execute_reply": "2022-07-04T13:06:55.958499Z"
    },
    "papermill": {
     "duration": 0.012215,
     "end_time": "2022-07-04T13:06:55.961217",
     "exception": false,
     "start_time": "2022-07-04T13:06:55.949002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DS(Dataset):\n",
    "    def __init__(self, images: np.ndarray, bboxes: np.ndarray, transform=None):\n",
    "        self.transform = transform\n",
    "        self.images = images\n",
    "        self.bboxes = bboxes\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.images[idx]), \\\n",
    "               torch.FloatTensor(self.bboxes[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9237bbf",
   "metadata": {
    "papermill": {
     "duration": 0.002994,
     "end_time": "2022-07-04T13:06:55.967612",
     "exception": false,
     "start_time": "2022-07-04T13:06:55.964618",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71871949",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T13:06:55.976131Z",
     "iopub.status.busy": "2022-07-04T13:06:55.975372Z",
     "iopub.status.idle": "2022-07-04T13:06:55.983093Z",
     "shell.execute_reply": "2022-07-04T13:06:55.982228Z"
    },
    "papermill": {
     "duration": 0.013729,
     "end_time": "2022-07-04T13:06:55.984960",
     "exception": false,
     "start_time": "2022-07-04T13:06:55.971231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_channels: int = 3):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.features = models.resnet50(pretrained=True, progress=True)\n",
    "        self.freeze()\n",
    "        self.features = nn.Sequential(*[*self.features.children()][:-1])\n",
    "        \n",
    "        # self.classifier = nn.Linear(in_features=self.features[-2][-1].bn3.num_features, out_features=3)\n",
    "        self.regressor = nn.Linear(in_features=self.features[-2][-1].bn3.num_features, out_features=4)\n",
    "    \n",
    "    def freeze(self):\n",
    "        for params in self.parameters(): params.requires_grad = False\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = nn.Flatten()(self.features(x))\n",
    "        reg_op = self.regressor(x)\n",
    "        \n",
    "        return reg_op"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f7ae84",
   "metadata": {
    "papermill": {
     "duration": 0.003008,
     "end_time": "2022-07-04T13:06:55.991138",
     "exception": false,
     "start_time": "2022-07-04T13:06:55.988130",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Fit and Predict Helper**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bbcc87f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T13:06:55.999004Z",
     "iopub.status.busy": "2022-07-04T13:06:55.998749Z",
     "iopub.status.idle": "2022-07-04T13:06:56.021050Z",
     "shell.execute_reply": "2022-07-04T13:06:56.020211Z"
    },
    "papermill": {
     "duration": 0.028703,
     "end_time": "2022-07-04T13:06:56.022983",
     "exception": false,
     "start_time": "2022-07-04T13:06:55.994280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit(model=None, \n",
    "        optimizer=None,\n",
    "        scheduler_rlrop=None,\n",
    "        scheduler_oclr=None, \n",
    "        epochs=None, \n",
    "        early_stopping_patience=None, \n",
    "        dataloaders=None, \n",
    "        fold=None, \n",
    "        device=None,\n",
    "        save_path=None,\n",
    "        verbose=False) -> tuple:\n",
    "    \n",
    "    if verbose:\n",
    "        breaker()\n",
    "        if fold: print(f\"Training Fold {fold}...\")\n",
    "        else: print(\"Training ...\")\n",
    "        breaker()\n",
    "        \n",
    "    bestLoss = {\"train\" : np.inf, \"valid\" : np.inf}\n",
    "    \n",
    "    Losses, LRs = [], []\n",
    "    \n",
    "    if fold: name = f\"state_fold_{fold}.pt\"\n",
    "    else: name = \"state.pt\"\n",
    "\n",
    "    start_time = time()\n",
    "    for e in range(epochs):\n",
    "        e_st = time()\n",
    "        epochLoss = {\"train\" : 0.0, \"valid\" : 0.0}\n",
    "\n",
    "        for phase in [\"train\", \"valid\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "    \n",
    "            lossPerPass = []\n",
    "            \n",
    "            for images, bboxes in dataloaders[phase]:\n",
    "                images, bboxes = images.to(device), bboxes.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    op_REG = model(images)\n",
    "                    loss = torch.nn.MSELoss()(op_REG, bboxes)\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        if scheduler_oclr: scheduler_oclr.step()\n",
    "                lossPerPass.append(loss.item())\n",
    "            epochLoss[phase] = np.mean(np.array(lossPerPass))\n",
    "        Losses.append(epochLoss)\n",
    "        \n",
    "        if scheduler_oclr:\n",
    "            save_dict = {\"model_state_dict\"     : model.state_dict(),\n",
    "                         \"optim_state_dict\"     : optimizer.state_dict(),\n",
    "                         \"scheduler_state_dict\" : scheduler_oclr.state_dict()}\n",
    "        \n",
    "        elif scheduler_rlrop:\n",
    "            save_dict = {\"model_state_dict\"     : model.state_dict(),\n",
    "                         \"optim_state_dict\"     : optimizer.state_dict(),\n",
    "                         \"scheduler_state_dict\" : scheduler_rlrop.state_dict()}\n",
    "        \n",
    "        else:\n",
    "            save_dict = {\"model_state_dict\"     : model.state_dict(),\n",
    "                         \"optim_state_dict\"     : optimizer.state_dict()}\n",
    "            \n",
    "        if early_stopping_patience:\n",
    "            if epochLoss[\"valid\"] < bestLoss[\"valid\"]:\n",
    "                bestLoss = epochLoss\n",
    "                BLE = e + 1\n",
    "                torch.save(save_dict, os.path.join(save_path, name))\n",
    "                early_stopping_step = 0\n",
    "            else:\n",
    "                early_stopping_step += 1\n",
    "                if early_stopping_step > early_stopping_patience:\n",
    "                    print(\"\\nEarly Stopping at Epoch {}\".format(e + 1))\n",
    "                    break\n",
    "        \n",
    "        if epochLoss[\"valid\"] < bestLoss[\"valid\"]:\n",
    "            bestLoss = epochLoss\n",
    "            BLE = e + 1\n",
    "            torch.save(save_dict, os.path.join(save_path, name))\n",
    "        \n",
    "        if scheduler_rlrop: scheduler_rlrop.step(epochLoss[\"valid\"])\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Epoch: {} | Train Loss: {:.5f} | Valid Loss: {:.5f} | Time: {:.2f} seconds\".format(e+1, epochLoss[\"train\"], epochLoss[\"valid\"], time()-e_st))\n",
    "\n",
    "    if verbose:                                           \n",
    "        breaker()\n",
    "        print(f\"Best Validation Loss at Epoch {BLE}\")\n",
    "        breaker()\n",
    "        print(\"Time Taken [{} Epochs] : {:.2f} minutes\".format(len(Losses), (time()-start_time)/60))\n",
    "    \n",
    "    return Losses, LRs, BLE, name\n",
    "\n",
    "def predict(model=None, device=None, image=None, size=None, path=None) -> np.ndarray:\n",
    "    model.load_state_dict(torch.load(path, map_location=device)[\"model_state_dict\"])\n",
    "    model.to(device)    \n",
    "    model.eval()\n",
    "    \n",
    "    h, w, _ = image.shape\n",
    "    temp_image = cv2.resize(src=image, dsize=(size, size), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        op_REG = model(transforms.ToTensor()(temp_image).unsqueeze(dim=0).to(cfg.device))\n",
    "    \n",
    "    op_REG = op_REG.detach().cpu().numpy().squeeze()\n",
    "    \n",
    "    return op_REG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc97cb0",
   "metadata": {
    "papermill": {
     "duration": 0.003438,
     "end_time": "2022-07-04T13:06:56.030111",
     "exception": false,
     "start_time": "2022-07-04T13:06:56.026673",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20f72dfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T13:06:56.038189Z",
     "iopub.status.busy": "2022-07-04T13:06:56.037568Z",
     "iopub.status.idle": "2022-07-04T13:06:57.839475Z",
     "shell.execute_reply": "2022-07-04T13:06:57.838493Z"
    },
    "papermill": {
     "duration": 1.808872,
     "end_time": "2022-07-04T13:06:57.842282",
     "exception": false,
     "start_time": "2022-07-04T13:06:56.033410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = np.load(os.path.join(cfg.train_path, f\"images_{SIZE}.npy\"))\n",
    "df = pd.read_csv(os.path.join(cfg.train_path, \"data.csv\"))\n",
    "bboxes = np.concatenate((\n",
    "    df.x1.copy().values.reshape(-1, 1),\n",
    "    df.y1.copy().values.reshape(-1, 1),\n",
    "    df.x2.copy().values.reshape(-1, 1),\n",
    "    df.y2.copy().values.reshape(-1, 1),\n",
    "), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b88e8631",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-04T13:06:57.852715Z",
     "iopub.status.busy": "2022-07-04T13:06:57.852068Z",
     "iopub.status.idle": "2022-07-04T13:31:48.489649Z",
     "shell.execute_reply": "2022-07-04T13:31:48.488434Z"
    },
    "papermill": {
     "duration": 1490.644845,
     "end_time": "2022-07-04T13:31:48.491676",
     "exception": false,
     "start_time": "2022-07-04T13:06:57.846831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357c2a3274894e97b4caa60d39628ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************************************************\n",
      "\n",
      "Training ...\n",
      "\n",
      "**************************************************\n",
      "\n",
      "Epoch: 1 | Train Loss: 0.21999 | Valid Loss: 0.16324 | Time: 9.26 seconds\n",
      "Epoch: 2 | Train Loss: 0.12108 | Valid Loss: 0.09248 | Time: 3.27 seconds\n",
      "Epoch: 3 | Train Loss: 0.07563 | Valid Loss: 0.06337 | Time: 3.18 seconds\n",
      "Epoch: 4 | Train Loss: 0.05696 | Valid Loss: 0.05205 | Time: 3.19 seconds\n",
      "Epoch: 5 | Train Loss: 0.05101 | Valid Loss: 0.04811 | Time: 3.26 seconds\n",
      "Epoch: 6 | Train Loss: 0.05100 | Valid Loss: 0.04646 | Time: 3.39 seconds\n",
      "Epoch: 7 | Train Loss: 0.04983 | Valid Loss: 0.04600 | Time: 3.11 seconds\n",
      "Epoch: 8 | Train Loss: 0.04923 | Valid Loss: 0.04484 | Time: 3.13 seconds\n",
      "Epoch: 9 | Train Loss: 0.04720 | Valid Loss: 0.04450 | Time: 3.07 seconds\n",
      "Epoch: 10 | Train Loss: 0.04693 | Valid Loss: 0.04394 | Time: 3.10 seconds\n",
      "Epoch: 11 | Train Loss: 0.04701 | Valid Loss: 0.04277 | Time: 3.05 seconds\n",
      "Epoch: 12 | Train Loss: 0.04531 | Valid Loss: 0.04223 | Time: 3.12 seconds\n",
      "Epoch: 13 | Train Loss: 0.04620 | Valid Loss: 0.04182 | Time: 3.05 seconds\n",
      "Epoch: 14 | Train Loss: 0.04538 | Valid Loss: 0.04120 | Time: 3.08 seconds\n",
      "Epoch: 15 | Train Loss: 0.04416 | Valid Loss: 0.04099 | Time: 3.09 seconds\n",
      "Epoch: 16 | Train Loss: 0.04411 | Valid Loss: 0.04068 | Time: 3.18 seconds\n",
      "Epoch: 17 | Train Loss: 0.04329 | Valid Loss: 0.04006 | Time: 3.17 seconds\n",
      "Epoch: 18 | Train Loss: 0.04291 | Valid Loss: 0.03963 | Time: 3.08 seconds\n",
      "Epoch: 19 | Train Loss: 0.04190 | Valid Loss: 0.03913 | Time: 3.09 seconds\n",
      "Epoch: 20 | Train Loss: 0.04280 | Valid Loss: 0.03803 | Time: 3.10 seconds\n",
      "Epoch: 21 | Train Loss: 0.04200 | Valid Loss: 0.03835 | Time: 2.86 seconds\n",
      "Epoch: 22 | Train Loss: 0.04091 | Valid Loss: 0.03786 | Time: 3.07 seconds\n",
      "Epoch: 23 | Train Loss: 0.04134 | Valid Loss: 0.03616 | Time: 3.13 seconds\n",
      "Epoch: 24 | Train Loss: 0.04004 | Valid Loss: 0.03667 | Time: 2.86 seconds\n",
      "Epoch: 25 | Train Loss: 0.03959 | Valid Loss: 0.03646 | Time: 2.83 seconds\n",
      "Epoch: 26 | Train Loss: 0.03943 | Valid Loss: 0.03578 | Time: 3.17 seconds\n",
      "Epoch: 27 | Train Loss: 0.03875 | Valid Loss: 0.03518 | Time: 3.25 seconds\n",
      "Epoch: 28 | Train Loss: 0.03821 | Valid Loss: 0.03510 | Time: 3.14 seconds\n",
      "Epoch: 29 | Train Loss: 0.03928 | Valid Loss: 0.03456 | Time: 3.05 seconds\n",
      "Epoch: 30 | Train Loss: 0.03752 | Valid Loss: 0.03456 | Time: 3.15 seconds\n",
      "Epoch: 31 | Train Loss: 0.03785 | Valid Loss: 0.03401 | Time: 3.04 seconds\n",
      "Epoch: 32 | Train Loss: 0.03686 | Valid Loss: 0.03403 | Time: 2.87 seconds\n",
      "Epoch: 33 | Train Loss: 0.03635 | Valid Loss: 0.03330 | Time: 3.06 seconds\n",
      "Epoch: 34 | Train Loss: 0.03703 | Valid Loss: 0.03337 | Time: 2.90 seconds\n",
      "Epoch: 35 | Train Loss: 0.03591 | Valid Loss: 0.03250 | Time: 3.18 seconds\n",
      "Epoch: 36 | Train Loss: 0.03523 | Valid Loss: 0.03268 | Time: 2.87 seconds\n",
      "Epoch: 37 | Train Loss: 0.03542 | Valid Loss: 0.03240 | Time: 3.14 seconds\n",
      "Epoch: 38 | Train Loss: 0.03539 | Valid Loss: 0.03251 | Time: 3.00 seconds\n",
      "Epoch: 39 | Train Loss: 0.03500 | Valid Loss: 0.03179 | Time: 3.09 seconds\n",
      "Epoch: 40 | Train Loss: 0.03393 | Valid Loss: 0.03144 | Time: 3.08 seconds\n",
      "Epoch: 41 | Train Loss: 0.03491 | Valid Loss: 0.03153 | Time: 2.96 seconds\n",
      "Epoch: 42 | Train Loss: 0.03388 | Valid Loss: 0.03126 | Time: 3.09 seconds\n",
      "Epoch: 43 | Train Loss: 0.03373 | Valid Loss: 0.03095 | Time: 3.10 seconds\n",
      "Epoch: 44 | Train Loss: 0.03307 | Valid Loss: 0.03048 | Time: 3.19 seconds\n",
      "Epoch: 45 | Train Loss: 0.03416 | Valid Loss: 0.03039 | Time: 3.12 seconds\n",
      "Epoch: 46 | Train Loss: 0.03346 | Valid Loss: 0.02999 | Time: 3.06 seconds\n",
      "Epoch: 47 | Train Loss: 0.03312 | Valid Loss: 0.02966 | Time: 3.07 seconds\n",
      "Epoch: 48 | Train Loss: 0.03245 | Valid Loss: 0.02983 | Time: 2.94 seconds\n",
      "Epoch: 49 | Train Loss: 0.03159 | Valid Loss: 0.02986 | Time: 2.92 seconds\n",
      "Epoch: 50 | Train Loss: 0.03151 | Valid Loss: 0.02889 | Time: 3.09 seconds\n",
      "Epoch: 51 | Train Loss: 0.03146 | Valid Loss: 0.02873 | Time: 3.09 seconds\n",
      "Epoch: 52 | Train Loss: 0.03135 | Valid Loss: 0.02853 | Time: 3.15 seconds\n",
      "Epoch: 53 | Train Loss: 0.03208 | Valid Loss: 0.02841 | Time: 3.09 seconds\n",
      "Epoch: 54 | Train Loss: 0.03101 | Valid Loss: 0.02857 | Time: 2.87 seconds\n",
      "Epoch: 55 | Train Loss: 0.03103 | Valid Loss: 0.02844 | Time: 2.90 seconds\n",
      "Epoch: 56 | Train Loss: 0.03000 | Valid Loss: 0.02844 | Time: 2.86 seconds\n",
      "Epoch: 57 | Train Loss: 0.03034 | Valid Loss: 0.02754 | Time: 3.08 seconds\n",
      "Epoch: 58 | Train Loss: 0.03045 | Valid Loss: 0.02819 | Time: 2.85 seconds\n",
      "Epoch: 59 | Train Loss: 0.03014 | Valid Loss: 0.02722 | Time: 3.34 seconds\n",
      "Epoch: 60 | Train Loss: 0.02952 | Valid Loss: 0.02791 | Time: 2.86 seconds\n",
      "Epoch: 61 | Train Loss: 0.02976 | Valid Loss: 0.02730 | Time: 2.84 seconds\n",
      "Epoch: 62 | Train Loss: 0.03024 | Valid Loss: 0.02727 | Time: 2.86 seconds\n",
      "Epoch: 63 | Train Loss: 0.02912 | Valid Loss: 0.02690 | Time: 3.15 seconds\n",
      "Epoch: 64 | Train Loss: 0.02882 | Valid Loss: 0.02695 | Time: 2.86 seconds\n",
      "Epoch: 65 | Train Loss: 0.02913 | Valid Loss: 0.02687 | Time: 3.21 seconds\n",
      "Epoch: 66 | Train Loss: 0.02888 | Valid Loss: 0.02651 | Time: 3.16 seconds\n",
      "Epoch: 67 | Train Loss: 0.02837 | Valid Loss: 0.02669 | Time: 2.85 seconds\n",
      "Epoch: 68 | Train Loss: 0.02845 | Valid Loss: 0.02643 | Time: 3.10 seconds\n",
      "Epoch: 69 | Train Loss: 0.02849 | Valid Loss: 0.02649 | Time: 2.87 seconds\n",
      "Epoch: 70 | Train Loss: 0.02822 | Valid Loss: 0.02576 | Time: 3.35 seconds\n",
      "Epoch: 71 | Train Loss: 0.02742 | Valid Loss: 0.02571 | Time: 3.10 seconds\n",
      "Epoch: 72 | Train Loss: 0.02817 | Valid Loss: 0.02583 | Time: 2.88 seconds\n",
      "Epoch: 73 | Train Loss: 0.02813 | Valid Loss: 0.02542 | Time: 3.10 seconds\n",
      "Epoch: 74 | Train Loss: 0.02693 | Valid Loss: 0.02553 | Time: 2.91 seconds\n",
      "Epoch: 75 | Train Loss: 0.02758 | Valid Loss: 0.02571 | Time: 2.85 seconds\n",
      "Epoch: 76 | Train Loss: 0.02706 | Valid Loss: 0.02535 | Time: 3.09 seconds\n",
      "Epoch: 77 | Train Loss: 0.02689 | Valid Loss: 0.02530 | Time: 3.14 seconds\n",
      "Epoch: 78 | Train Loss: 0.02615 | Valid Loss: 0.02505 | Time: 3.05 seconds\n",
      "Epoch: 79 | Train Loss: 0.02572 | Valid Loss: 0.02478 | Time: 3.11 seconds\n",
      "Epoch: 80 | Train Loss: 0.02622 | Valid Loss: 0.02487 | Time: 2.85 seconds\n",
      "Epoch: 81 | Train Loss: 0.02682 | Valid Loss: 0.02462 | Time: 3.32 seconds\n",
      "Epoch: 82 | Train Loss: 0.02602 | Valid Loss: 0.02492 | Time: 2.86 seconds\n",
      "Epoch: 83 | Train Loss: 0.02526 | Valid Loss: 0.02411 | Time: 3.09 seconds\n",
      "Epoch: 84 | Train Loss: 0.02568 | Valid Loss: 0.02402 | Time: 3.20 seconds\n",
      "Epoch: 85 | Train Loss: 0.02535 | Valid Loss: 0.02438 | Time: 2.88 seconds\n",
      "Epoch: 86 | Train Loss: 0.02603 | Valid Loss: 0.02407 | Time: 2.85 seconds\n",
      "Epoch: 87 | Train Loss: 0.02490 | Valid Loss: 0.02408 | Time: 2.86 seconds\n",
      "Epoch: 88 | Train Loss: 0.02549 | Valid Loss: 0.02409 | Time: 2.92 seconds\n",
      "Epoch: 89 | Train Loss: 0.02584 | Valid Loss: 0.02431 | Time: 2.87 seconds\n",
      "Epoch: 90 | Train Loss: 0.02520 | Valid Loss: 0.02351 | Time: 3.10 seconds\n",
      "Epoch: 91 | Train Loss: 0.02485 | Valid Loss: 0.02373 | Time: 2.87 seconds\n",
      "Epoch: 92 | Train Loss: 0.02491 | Valid Loss: 0.02372 | Time: 3.18 seconds\n",
      "Epoch: 93 | Train Loss: 0.02414 | Valid Loss: 0.02378 | Time: 2.84 seconds\n",
      "Epoch: 94 | Train Loss: 0.02469 | Valid Loss: 0.02331 | Time: 3.10 seconds\n",
      "Epoch: 95 | Train Loss: 0.02442 | Valid Loss: 0.02353 | Time: 2.86 seconds\n",
      "Epoch: 96 | Train Loss: 0.02410 | Valid Loss: 0.02301 | Time: 3.13 seconds\n",
      "Epoch: 97 | Train Loss: 0.02439 | Valid Loss: 0.02293 | Time: 3.10 seconds\n",
      "Epoch: 98 | Train Loss: 0.02369 | Valid Loss: 0.02316 | Time: 2.86 seconds\n",
      "Epoch: 99 | Train Loss: 0.02328 | Valid Loss: 0.02271 | Time: 3.15 seconds\n",
      "Epoch: 100 | Train Loss: 0.02380 | Valid Loss: 0.02315 | Time: 2.85 seconds\n",
      "Epoch: 101 | Train Loss: 0.02344 | Valid Loss: 0.02244 | Time: 3.07 seconds\n",
      "Epoch: 102 | Train Loss: 0.02383 | Valid Loss: 0.02247 | Time: 2.86 seconds\n",
      "Epoch: 103 | Train Loss: 0.02361 | Valid Loss: 0.02267 | Time: 3.18 seconds\n",
      "Epoch: 104 | Train Loss: 0.02428 | Valid Loss: 0.02245 | Time: 2.85 seconds\n",
      "Epoch: 105 | Train Loss: 0.02251 | Valid Loss: 0.02248 | Time: 2.85 seconds\n",
      "Epoch: 106 | Train Loss: 0.02335 | Valid Loss: 0.02244 | Time: 2.86 seconds\n",
      "Epoch: 107 | Train Loss: 0.02319 | Valid Loss: 0.02229 | Time: 3.12 seconds\n",
      "Epoch: 108 | Train Loss: 0.02245 | Valid Loss: 0.02198 | Time: 3.09 seconds\n",
      "Epoch: 109 | Train Loss: 0.02289 | Valid Loss: 0.02196 | Time: 3.07 seconds\n",
      "Epoch: 110 | Train Loss: 0.02294 | Valid Loss: 0.02208 | Time: 2.93 seconds\n",
      "Epoch: 111 | Train Loss: 0.02247 | Valid Loss: 0.02202 | Time: 2.88 seconds\n",
      "Epoch: 112 | Train Loss: 0.02257 | Valid Loss: 0.02180 | Time: 3.08 seconds\n",
      "Epoch: 113 | Train Loss: 0.02247 | Valid Loss: 0.02180 | Time: 2.87 seconds\n",
      "Epoch: 114 | Train Loss: 0.02230 | Valid Loss: 0.02190 | Time: 3.22 seconds\n",
      "Epoch: 115 | Train Loss: 0.02189 | Valid Loss: 0.02159 | Time: 3.13 seconds\n",
      "Epoch: 116 | Train Loss: 0.02195 | Valid Loss: 0.02159 | Time: 3.13 seconds\n",
      "Epoch: 117 | Train Loss: 0.02207 | Valid Loss: 0.02186 | Time: 2.90 seconds\n",
      "Epoch: 118 | Train Loss: 0.02172 | Valid Loss: 0.02185 | Time: 2.93 seconds\n",
      "Epoch: 119 | Train Loss: 0.02201 | Valid Loss: 0.02178 | Time: 2.87 seconds\n",
      "Epoch: 120 | Train Loss: 0.02134 | Valid Loss: 0.02144 | Time: 3.12 seconds\n",
      "Epoch: 121 | Train Loss: 0.02107 | Valid Loss: 0.02153 | Time: 2.91 seconds\n",
      "Epoch: 122 | Train Loss: 0.02222 | Valid Loss: 0.02102 | Time: 3.08 seconds\n",
      "Epoch: 123 | Train Loss: 0.02150 | Valid Loss: 0.02188 | Time: 2.89 seconds\n",
      "Epoch: 124 | Train Loss: 0.02162 | Valid Loss: 0.02099 | Time: 3.10 seconds\n",
      "Epoch: 125 | Train Loss: 0.02187 | Valid Loss: 0.02100 | Time: 3.15 seconds\n",
      "Epoch: 126 | Train Loss: 0.02125 | Valid Loss: 0.02146 | Time: 2.85 seconds\n",
      "Epoch: 127 | Train Loss: 0.02143 | Valid Loss: 0.02072 | Time: 3.09 seconds\n",
      "Epoch: 128 | Train Loss: 0.02066 | Valid Loss: 0.02102 | Time: 2.85 seconds\n",
      "Epoch: 129 | Train Loss: 0.02106 | Valid Loss: 0.02061 | Time: 3.13 seconds\n",
      "Epoch: 130 | Train Loss: 0.02111 | Valid Loss: 0.02108 | Time: 2.86 seconds\n",
      "Epoch: 131 | Train Loss: 0.02086 | Valid Loss: 0.02064 | Time: 2.85 seconds\n",
      "Epoch: 132 | Train Loss: 0.02048 | Valid Loss: 0.02080 | Time: 2.91 seconds\n",
      "Epoch: 133 | Train Loss: 0.02077 | Valid Loss: 0.02031 | Time: 3.09 seconds\n",
      "Epoch: 134 | Train Loss: 0.02042 | Valid Loss: 0.02076 | Time: 2.86 seconds\n",
      "Epoch: 135 | Train Loss: 0.02120 | Valid Loss: 0.02076 | Time: 2.85 seconds\n",
      "Epoch: 136 | Train Loss: 0.02103 | Valid Loss: 0.02024 | Time: 3.46 seconds\n",
      "Epoch: 137 | Train Loss: 0.02095 | Valid Loss: 0.02055 | Time: 2.85 seconds\n",
      "Epoch: 138 | Train Loss: 0.01970 | Valid Loss: 0.02019 | Time: 3.17 seconds\n",
      "Epoch: 139 | Train Loss: 0.02014 | Valid Loss: 0.02050 | Time: 2.89 seconds\n",
      "Epoch: 140 | Train Loss: 0.01996 | Valid Loss: 0.02027 | Time: 2.90 seconds\n",
      "Epoch: 141 | Train Loss: 0.01989 | Valid Loss: 0.02029 | Time: 2.85 seconds\n",
      "Epoch: 142 | Train Loss: 0.02012 | Valid Loss: 0.02029 | Time: 2.83 seconds\n",
      "Epoch: 143 | Train Loss: 0.02031 | Valid Loss: 0.02015 | Time: 3.23 seconds\n",
      "Epoch: 144 | Train Loss: 0.02021 | Valid Loss: 0.02051 | Time: 2.84 seconds\n",
      "Epoch: 145 | Train Loss: 0.01976 | Valid Loss: 0.01997 | Time: 3.26 seconds\n",
      "Epoch: 146 | Train Loss: 0.02038 | Valid Loss: 0.02014 | Time: 2.85 seconds\n",
      "Epoch: 147 | Train Loss: 0.01942 | Valid Loss: 0.02019 | Time: 3.17 seconds\n",
      "Epoch: 148 | Train Loss: 0.01960 | Valid Loss: 0.01995 | Time: 3.09 seconds\n",
      "Epoch: 149 | Train Loss: 0.02007 | Valid Loss: 0.02009 | Time: 2.87 seconds\n",
      "Epoch: 150 | Train Loss: 0.01966 | Valid Loss: 0.01975 | Time: 3.06 seconds\n",
      "Epoch: 151 | Train Loss: 0.01952 | Valid Loss: 0.01968 | Time: 3.18 seconds\n",
      "Epoch: 152 | Train Loss: 0.01968 | Valid Loss: 0.02003 | Time: 2.85 seconds\n",
      "Epoch: 153 | Train Loss: 0.01949 | Valid Loss: 0.02026 | Time: 2.84 seconds\n",
      "Epoch: 154 | Train Loss: 0.01935 | Valid Loss: 0.01956 | Time: 3.16 seconds\n",
      "Epoch: 155 | Train Loss: 0.01930 | Valid Loss: 0.01983 | Time: 2.83 seconds\n",
      "Epoch: 156 | Train Loss: 0.01956 | Valid Loss: 0.01994 | Time: 2.87 seconds\n",
      "Epoch: 157 | Train Loss: 0.01945 | Valid Loss: 0.01973 | Time: 2.88 seconds\n",
      "Epoch: 158 | Train Loss: 0.01891 | Valid Loss: 0.01938 | Time: 3.32 seconds\n",
      "Epoch: 159 | Train Loss: 0.01874 | Valid Loss: 0.01984 | Time: 2.84 seconds\n",
      "Epoch: 160 | Train Loss: 0.01919 | Valid Loss: 0.01953 | Time: 2.82 seconds\n",
      "Epoch: 161 | Train Loss: 0.01941 | Valid Loss: 0.01944 | Time: 2.84 seconds\n",
      "Epoch: 162 | Train Loss: 0.01940 | Valid Loss: 0.01930 | Time: 3.14 seconds\n",
      "Epoch: 163 | Train Loss: 0.01865 | Valid Loss: 0.01944 | Time: 2.85 seconds\n",
      "Epoch: 164 | Train Loss: 0.01877 | Valid Loss: 0.01907 | Time: 3.08 seconds\n",
      "Epoch: 165 | Train Loss: 0.01849 | Valid Loss: 0.01923 | Time: 2.86 seconds\n",
      "Epoch: 166 | Train Loss: 0.01861 | Valid Loss: 0.01945 | Time: 2.89 seconds\n",
      "Epoch: 167 | Train Loss: 0.01843 | Valid Loss: 0.01923 | Time: 2.85 seconds\n",
      "Epoch: 168 | Train Loss: 0.01838 | Valid Loss: 0.01943 | Time: 2.86 seconds\n",
      "Epoch: 169 | Train Loss: 0.01841 | Valid Loss: 0.01903 | Time: 3.25 seconds\n",
      "Epoch: 170 | Train Loss: 0.01874 | Valid Loss: 0.01933 | Time: 2.85 seconds\n",
      "Epoch: 171 | Train Loss: 0.01832 | Valid Loss: 0.01893 | Time: 3.06 seconds\n",
      "Epoch: 172 | Train Loss: 0.01848 | Valid Loss: 0.01898 | Time: 2.89 seconds\n",
      "Epoch: 173 | Train Loss: 0.01827 | Valid Loss: 0.01912 | Time: 2.94 seconds\n",
      "Epoch: 174 | Train Loss: 0.01856 | Valid Loss: 0.01894 | Time: 2.87 seconds\n",
      "Epoch: 175 | Train Loss: 0.01794 | Valid Loss: 0.01901 | Time: 2.86 seconds\n",
      "Epoch: 176 | Train Loss: 0.01927 | Valid Loss: 0.01939 | Time: 2.87 seconds\n",
      "Epoch: 177 | Train Loss: 0.01782 | Valid Loss: 0.01869 | Time: 3.21 seconds\n",
      "Epoch: 178 | Train Loss: 0.01857 | Valid Loss: 0.01909 | Time: 2.86 seconds\n",
      "Epoch: 179 | Train Loss: 0.01840 | Valid Loss: 0.01879 | Time: 2.88 seconds\n",
      "Epoch: 180 | Train Loss: 0.01797 | Valid Loss: 0.01870 | Time: 2.96 seconds\n",
      "Epoch: 181 | Train Loss: 0.01815 | Valid Loss: 0.01857 | Time: 3.13 seconds\n",
      "Epoch: 182 | Train Loss: 0.01834 | Valid Loss: 0.01847 | Time: 3.09 seconds\n",
      "Epoch: 183 | Train Loss: 0.01842 | Valid Loss: 0.01838 | Time: 3.09 seconds\n",
      "Epoch: 184 | Train Loss: 0.01763 | Valid Loss: 0.01865 | Time: 2.94 seconds\n",
      "Epoch: 185 | Train Loss: 0.01834 | Valid Loss: 0.01824 | Time: 3.24 seconds\n",
      "Epoch: 186 | Train Loss: 0.01755 | Valid Loss: 0.01872 | Time: 2.89 seconds\n",
      "Epoch: 187 | Train Loss: 0.01753 | Valid Loss: 0.01847 | Time: 2.86 seconds\n",
      "Epoch: 188 | Train Loss: 0.01723 | Valid Loss: 0.01880 | Time: 2.93 seconds\n",
      "Epoch: 189 | Train Loss: 0.01737 | Valid Loss: 0.01873 | Time: 2.87 seconds\n",
      "Epoch: 190 | Train Loss: 0.01724 | Valid Loss: 0.01833 | Time: 2.88 seconds\n",
      "Epoch: 191 | Train Loss: 0.01799 | Valid Loss: 0.01905 | Time: 3.00 seconds\n",
      "Epoch: 192 | Train Loss: 0.01726 | Valid Loss: 0.01823 | Time: 3.15 seconds\n",
      "Epoch: 193 | Train Loss: 0.01768 | Valid Loss: 0.01845 | Time: 2.88 seconds\n",
      "Epoch: 194 | Train Loss: 0.01777 | Valid Loss: 0.01846 | Time: 2.87 seconds\n",
      "Epoch: 195 | Train Loss: 0.01712 | Valid Loss: 0.01831 | Time: 2.91 seconds\n",
      "Epoch: 196 | Train Loss: 0.01744 | Valid Loss: 0.01857 | Time: 2.83 seconds\n",
      "Epoch: 197 | Train Loss: 0.01727 | Valid Loss: 0.01803 | Time: 3.09 seconds\n",
      "Epoch: 198 | Train Loss: 0.01746 | Valid Loss: 0.01822 | Time: 2.85 seconds\n",
      "Epoch: 199 | Train Loss: 0.01740 | Valid Loss: 0.01839 | Time: 2.93 seconds\n",
      "Epoch: 200 | Train Loss: 0.01780 | Valid Loss: 0.01817 | Time: 2.85 seconds\n",
      "Epoch: 201 | Train Loss: 0.01698 | Valid Loss: 0.01867 | Time: 2.88 seconds\n",
      "Epoch: 202 | Train Loss: 0.01732 | Valid Loss: 0.01814 | Time: 2.90 seconds\n",
      "Epoch: 203 | Train Loss: 0.01737 | Valid Loss: 0.01852 | Time: 2.95 seconds\n",
      "Epoch: 204 | Train Loss: 0.01743 | Valid Loss: 0.01805 | Time: 2.87 seconds\n",
      "Epoch: 205 | Train Loss: 0.01782 | Valid Loss: 0.01865 | Time: 2.84 seconds\n",
      "Epoch: 206 | Train Loss: 0.01774 | Valid Loss: 0.01805 | Time: 2.87 seconds\n",
      "Epoch: 207 | Train Loss: 0.01724 | Valid Loss: 0.01782 | Time: 3.12 seconds\n",
      "Epoch: 208 | Train Loss: 0.01748 | Valid Loss: 0.01848 | Time: 2.87 seconds\n",
      "Epoch: 209 | Train Loss: 0.01661 | Valid Loss: 0.01795 | Time: 2.84 seconds\n",
      "Epoch: 210 | Train Loss: 0.01692 | Valid Loss: 0.01839 | Time: 2.90 seconds\n",
      "Epoch: 211 | Train Loss: 0.01721 | Valid Loss: 0.01800 | Time: 2.86 seconds\n",
      "Epoch: 212 | Train Loss: 0.01695 | Valid Loss: 0.01842 | Time: 2.85 seconds\n",
      "Epoch: 213 | Train Loss: 0.01596 | Valid Loss: 0.01797 | Time: 2.95 seconds\n",
      "Epoch: 214 | Train Loss: 0.01699 | Valid Loss: 0.01785 | Time: 2.90 seconds\n",
      "Epoch: 215 | Train Loss: 0.01660 | Valid Loss: 0.01776 | Time: 3.09 seconds\n",
      "Epoch: 216 | Train Loss: 0.01621 | Valid Loss: 0.01789 | Time: 2.84 seconds\n",
      "Epoch: 217 | Train Loss: 0.01623 | Valid Loss: 0.01794 | Time: 2.87 seconds\n",
      "Epoch: 218 | Train Loss: 0.01629 | Valid Loss: 0.01780 | Time: 2.90 seconds\n",
      "Epoch: 219 | Train Loss: 0.01663 | Valid Loss: 0.01794 | Time: 2.85 seconds\n",
      "Epoch: 220 | Train Loss: 0.01630 | Valid Loss: 0.01790 | Time: 2.86 seconds\n",
      "Epoch: 221 | Train Loss: 0.01612 | Valid Loss: 0.01817 | Time: 2.84 seconds\n",
      "Epoch: 222 | Train Loss: 0.01619 | Valid Loss: 0.01807 | Time: 2.90 seconds\n",
      "Epoch: 223 | Train Loss: 0.01579 | Valid Loss: 0.01771 | Time: 3.09 seconds\n",
      "Epoch: 224 | Train Loss: 0.01620 | Valid Loss: 0.01793 | Time: 2.94 seconds\n",
      "Epoch: 225 | Train Loss: 0.01623 | Valid Loss: 0.01772 | Time: 2.88 seconds\n",
      "Epoch: 226 | Train Loss: 0.01649 | Valid Loss: 0.01741 | Time: 3.12 seconds\n",
      "Epoch: 227 | Train Loss: 0.01622 | Valid Loss: 0.01786 | Time: 2.87 seconds\n",
      "Epoch: 228 | Train Loss: 0.01608 | Valid Loss: 0.01756 | Time: 2.85 seconds\n",
      "Epoch: 229 | Train Loss: 0.01610 | Valid Loss: 0.01761 | Time: 2.90 seconds\n",
      "Epoch: 230 | Train Loss: 0.01593 | Valid Loss: 0.01754 | Time: 2.84 seconds\n",
      "Epoch: 231 | Train Loss: 0.01596 | Valid Loss: 0.01751 | Time: 2.86 seconds\n",
      "Epoch: 232 | Train Loss: 0.01524 | Valid Loss: 0.01791 | Time: 2.85 seconds\n",
      "Epoch: 233 | Train Loss: 0.01558 | Valid Loss: 0.01767 | Time: 2.92 seconds\n",
      "Epoch: 234 | Train Loss: 0.01518 | Valid Loss: 0.01774 | Time: 2.85 seconds\n",
      "Epoch: 235 | Train Loss: 0.01590 | Valid Loss: 0.01775 | Time: 2.90 seconds\n",
      "Epoch: 236 | Train Loss: 0.01576 | Valid Loss: 0.01748 | Time: 2.88 seconds\n",
      "Epoch: 237 | Train Loss: 0.01508 | Valid Loss: 0.01731 | Time: 3.14 seconds\n",
      "Epoch: 238 | Train Loss: 0.01616 | Valid Loss: 0.01786 | Time: 2.86 seconds\n",
      "Epoch: 239 | Train Loss: 0.01609 | Valid Loss: 0.01747 | Time: 2.84 seconds\n",
      "Epoch: 240 | Train Loss: 0.01605 | Valid Loss: 0.01813 | Time: 2.86 seconds\n",
      "Epoch: 241 | Train Loss: 0.01567 | Valid Loss: 0.01740 | Time: 2.88 seconds\n",
      "Epoch: 242 | Train Loss: 0.01628 | Valid Loss: 0.01750 | Time: 2.84 seconds\n",
      "Epoch: 243 | Train Loss: 0.01598 | Valid Loss: 0.01782 | Time: 2.84 seconds\n",
      "Epoch: 244 | Train Loss: 0.01585 | Valid Loss: 0.01737 | Time: 2.84 seconds\n",
      "Epoch: 245 | Train Loss: 0.01602 | Valid Loss: 0.01745 | Time: 2.89 seconds\n",
      "Epoch: 246 | Train Loss: 0.01551 | Valid Loss: 0.01722 | Time: 3.08 seconds\n",
      "Epoch: 247 | Train Loss: 0.01543 | Valid Loss: 0.01776 | Time: 2.94 seconds\n",
      "Epoch: 248 | Train Loss: 0.01586 | Valid Loss: 0.01723 | Time: 2.90 seconds\n",
      "Epoch: 249 | Train Loss: 0.01556 | Valid Loss: 0.01744 | Time: 2.85 seconds\n",
      "Epoch: 250 | Train Loss: 0.01534 | Valid Loss: 0.01755 | Time: 2.85 seconds\n",
      "Epoch: 251 | Train Loss: 0.01543 | Valid Loss: 0.01748 | Time: 2.86 seconds\n",
      "Epoch: 252 | Train Loss: 0.01582 | Valid Loss: 0.01765 | Time: 2.89 seconds\n",
      "Epoch: 253 | Train Loss: 0.01501 | Valid Loss: 0.01731 | Time: 2.83 seconds\n",
      "Epoch: 254 | Train Loss: 0.01536 | Valid Loss: 0.01741 | Time: 2.85 seconds\n",
      "Epoch: 255 | Train Loss: 0.01522 | Valid Loss: 0.01766 | Time: 2.85 seconds\n",
      "Epoch: 256 | Train Loss: 0.01524 | Valid Loss: 0.01740 | Time: 2.89 seconds\n",
      "Epoch: 257 | Train Loss: 0.01514 | Valid Loss: 0.01719 | Time: 3.09 seconds\n",
      "Epoch: 258 | Train Loss: 0.01512 | Valid Loss: 0.01712 | Time: 3.17 seconds\n",
      "Epoch: 259 | Train Loss: 0.01540 | Valid Loss: 0.01744 | Time: 2.86 seconds\n",
      "Epoch: 260 | Train Loss: 0.01465 | Valid Loss: 0.01694 | Time: 3.16 seconds\n",
      "Epoch: 261 | Train Loss: 0.01522 | Valid Loss: 0.01732 | Time: 2.86 seconds\n",
      "Epoch: 262 | Train Loss: 0.01523 | Valid Loss: 0.01705 | Time: 2.85 seconds\n",
      "Epoch: 263 | Train Loss: 0.01536 | Valid Loss: 0.01712 | Time: 2.90 seconds\n",
      "Epoch: 264 | Train Loss: 0.01518 | Valid Loss: 0.01751 | Time: 2.83 seconds\n",
      "Epoch: 265 | Train Loss: 0.01572 | Valid Loss: 0.01718 | Time: 2.85 seconds\n",
      "Epoch: 266 | Train Loss: 0.01532 | Valid Loss: 0.01722 | Time: 2.84 seconds\n",
      "Epoch: 267 | Train Loss: 0.01522 | Valid Loss: 0.01727 | Time: 2.90 seconds\n",
      "Epoch: 268 | Train Loss: 0.01492 | Valid Loss: 0.01724 | Time: 2.85 seconds\n",
      "Epoch: 269 | Train Loss: 0.01472 | Valid Loss: 0.01697 | Time: 2.84 seconds\n",
      "Epoch: 270 | Train Loss: 0.01480 | Valid Loss: 0.01736 | Time: 2.85 seconds\n",
      "Epoch: 271 | Train Loss: 0.01483 | Valid Loss: 0.01709 | Time: 2.89 seconds\n",
      "Epoch: 272 | Train Loss: 0.01482 | Valid Loss: 0.01726 | Time: 2.86 seconds\n",
      "Epoch: 273 | Train Loss: 0.01482 | Valid Loss: 0.01718 | Time: 2.93 seconds\n",
      "Epoch: 274 | Train Loss: 0.01489 | Valid Loss: 0.01715 | Time: 2.84 seconds\n",
      "Epoch: 275 | Train Loss: 0.01452 | Valid Loss: 0.01715 | Time: 2.92 seconds\n",
      "Epoch: 276 | Train Loss: 0.01495 | Valid Loss: 0.01691 | Time: 3.08 seconds\n",
      "Epoch: 277 | Train Loss: 0.01452 | Valid Loss: 0.01713 | Time: 2.84 seconds\n",
      "Epoch: 278 | Train Loss: 0.01464 | Valid Loss: 0.01716 | Time: 2.85 seconds\n",
      "Epoch: 279 | Train Loss: 0.01429 | Valid Loss: 0.01720 | Time: 2.91 seconds\n",
      "Epoch: 280 | Train Loss: 0.01414 | Valid Loss: 0.01684 | Time: 3.09 seconds\n",
      "Epoch: 281 | Train Loss: 0.01507 | Valid Loss: 0.01742 | Time: 2.86 seconds\n",
      "Epoch: 282 | Train Loss: 0.01417 | Valid Loss: 0.01692 | Time: 2.92 seconds\n",
      "Epoch: 283 | Train Loss: 0.01418 | Valid Loss: 0.01692 | Time: 2.86 seconds\n",
      "Epoch: 284 | Train Loss: 0.01467 | Valid Loss: 0.01723 | Time: 2.91 seconds\n",
      "Epoch: 285 | Train Loss: 0.01537 | Valid Loss: 0.01716 | Time: 2.86 seconds\n",
      "Epoch: 286 | Train Loss: 0.01473 | Valid Loss: 0.01690 | Time: 2.90 seconds\n",
      "Epoch: 287 | Train Loss: 0.01486 | Valid Loss: 0.01721 | Time: 2.85 seconds\n",
      "Epoch: 288 | Train Loss: 0.01425 | Valid Loss: 0.01732 | Time: 2.85 seconds\n",
      "Epoch: 289 | Train Loss: 0.01535 | Valid Loss: 0.01683 | Time: 3.10 seconds\n",
      "Epoch: 290 | Train Loss: 0.01469 | Valid Loss: 0.01732 | Time: 2.91 seconds\n",
      "Epoch: 291 | Train Loss: 0.01463 | Valid Loss: 0.01746 | Time: 2.83 seconds\n",
      "Epoch: 292 | Train Loss: 0.01428 | Valid Loss: 0.01687 | Time: 2.84 seconds\n",
      "Epoch: 293 | Train Loss: 0.01427 | Valid Loss: 0.01709 | Time: 2.86 seconds\n",
      "Epoch: 294 | Train Loss: 0.01475 | Valid Loss: 0.01673 | Time: 3.15 seconds\n",
      "Epoch: 295 | Train Loss: 0.01435 | Valid Loss: 0.01724 | Time: 2.89 seconds\n",
      "Epoch: 296 | Train Loss: 0.01434 | Valid Loss: 0.01702 | Time: 2.93 seconds\n",
      "Epoch: 297 | Train Loss: 0.01442 | Valid Loss: 0.01717 | Time: 2.88 seconds\n",
      "Epoch: 298 | Train Loss: 0.01475 | Valid Loss: 0.01723 | Time: 2.86 seconds\n",
      "Epoch: 299 | Train Loss: 0.01395 | Valid Loss: 0.01713 | Time: 2.86 seconds\n",
      "Epoch: 300 | Train Loss: 0.01495 | Valid Loss: 0.01726 | Time: 2.85 seconds\n",
      "Epoch: 301 | Train Loss: 0.01426 | Valid Loss: 0.01685 | Time: 2.89 seconds\n",
      "Epoch: 302 | Train Loss: 0.01478 | Valid Loss: 0.01703 | Time: 2.84 seconds\n",
      "Epoch: 303 | Train Loss: 0.01437 | Valid Loss: 0.01709 | Time: 2.84 seconds\n",
      "Epoch: 304 | Train Loss: 0.01465 | Valid Loss: 0.01687 | Time: 2.85 seconds\n",
      "Epoch: 305 | Train Loss: 0.01413 | Valid Loss: 0.01685 | Time: 2.90 seconds\n",
      "Epoch: 306 | Train Loss: 0.01406 | Valid Loss: 0.01705 | Time: 2.86 seconds\n",
      "Epoch: 307 | Train Loss: 0.01375 | Valid Loss: 0.01681 | Time: 2.93 seconds\n",
      "Epoch: 308 | Train Loss: 0.01411 | Valid Loss: 0.01711 | Time: 2.85 seconds\n",
      "Epoch: 309 | Train Loss: 0.01390 | Valid Loss: 0.01702 | Time: 2.91 seconds\n",
      "Epoch: 310 | Train Loss: 0.01361 | Valid Loss: 0.01670 | Time: 3.12 seconds\n",
      "Epoch: 311 | Train Loss: 0.01400 | Valid Loss: 0.01671 | Time: 2.87 seconds\n",
      "Epoch: 312 | Train Loss: 0.01399 | Valid Loss: 0.01688 | Time: 2.89 seconds\n",
      "Epoch: 313 | Train Loss: 0.01340 | Valid Loss: 0.01674 | Time: 2.97 seconds\n",
      "Epoch: 314 | Train Loss: 0.01415 | Valid Loss: 0.01661 | Time: 3.11 seconds\n",
      "Epoch: 315 | Train Loss: 0.01432 | Valid Loss: 0.01662 | Time: 2.87 seconds\n",
      "Epoch: 316 | Train Loss: 0.01385 | Valid Loss: 0.01660 | Time: 3.26 seconds\n",
      "Epoch: 317 | Train Loss: 0.01413 | Valid Loss: 0.01703 | Time: 2.88 seconds\n",
      "Epoch: 318 | Train Loss: 0.01399 | Valid Loss: 0.01657 | Time: 3.24 seconds\n",
      "Epoch: 319 | Train Loss: 0.01412 | Valid Loss: 0.01712 | Time: 2.98 seconds\n",
      "Epoch: 320 | Train Loss: 0.01399 | Valid Loss: 0.01684 | Time: 2.93 seconds\n",
      "Epoch: 321 | Train Loss: 0.01336 | Valid Loss: 0.01694 | Time: 2.86 seconds\n",
      "Epoch: 322 | Train Loss: 0.01337 | Valid Loss: 0.01667 | Time: 2.87 seconds\n",
      "Epoch: 323 | Train Loss: 0.01389 | Valid Loss: 0.01689 | Time: 2.87 seconds\n",
      "Epoch: 324 | Train Loss: 0.01433 | Valid Loss: 0.01666 | Time: 2.93 seconds\n",
      "Epoch: 325 | Train Loss: 0.01448 | Valid Loss: 0.01677 | Time: 2.86 seconds\n",
      "Epoch: 326 | Train Loss: 0.01437 | Valid Loss: 0.01645 | Time: 3.12 seconds\n",
      "Epoch: 327 | Train Loss: 0.01367 | Valid Loss: 0.01690 | Time: 2.88 seconds\n",
      "Epoch: 328 | Train Loss: 0.01360 | Valid Loss: 0.01679 | Time: 2.88 seconds\n",
      "Epoch: 329 | Train Loss: 0.01386 | Valid Loss: 0.01676 | Time: 2.85 seconds\n",
      "Epoch: 330 | Train Loss: 0.01357 | Valid Loss: 0.01702 | Time: 2.93 seconds\n",
      "Epoch: 331 | Train Loss: 0.01373 | Valid Loss: 0.01646 | Time: 2.92 seconds\n",
      "Epoch: 332 | Train Loss: 0.01308 | Valid Loss: 0.01721 | Time: 2.84 seconds\n",
      "Epoch: 333 | Train Loss: 0.01357 | Valid Loss: 0.01690 | Time: 2.86 seconds\n",
      "Epoch: 334 | Train Loss: 0.01314 | Valid Loss: 0.01684 | Time: 2.84 seconds\n",
      "Epoch: 335 | Train Loss: 0.01298 | Valid Loss: 0.01647 | Time: 2.93 seconds\n",
      "Epoch: 336 | Train Loss: 0.01292 | Valid Loss: 0.01679 | Time: 2.87 seconds\n",
      "Epoch: 337 | Train Loss: 0.01321 | Valid Loss: 0.01706 | Time: 2.85 seconds\n",
      "Epoch: 338 | Train Loss: 0.01335 | Valid Loss: 0.01684 | Time: 2.87 seconds\n",
      "Epoch: 339 | Train Loss: 0.01299 | Valid Loss: 0.01665 | Time: 2.89 seconds\n",
      "Epoch: 340 | Train Loss: 0.01339 | Valid Loss: 0.01659 | Time: 2.86 seconds\n",
      "Epoch: 341 | Train Loss: 0.01430 | Valid Loss: 0.01682 | Time: 2.93 seconds\n",
      "Epoch: 342 | Train Loss: 0.01329 | Valid Loss: 0.01671 | Time: 2.85 seconds\n",
      "Epoch: 343 | Train Loss: 0.01331 | Valid Loss: 0.01715 | Time: 2.91 seconds\n",
      "Epoch: 344 | Train Loss: 0.01400 | Valid Loss: 0.01691 | Time: 2.84 seconds\n",
      "Epoch: 345 | Train Loss: 0.01398 | Valid Loss: 0.01649 | Time: 2.87 seconds\n",
      "Epoch: 346 | Train Loss: 0.01371 | Valid Loss: 0.01701 | Time: 2.83 seconds\n",
      "Epoch: 347 | Train Loss: 0.01356 | Valid Loss: 0.01659 | Time: 2.89 seconds\n",
      "Epoch: 348 | Train Loss: 0.01358 | Valid Loss: 0.01634 | Time: 3.09 seconds\n",
      "Epoch: 349 | Train Loss: 0.01309 | Valid Loss: 0.01704 | Time: 2.87 seconds\n",
      "Epoch: 350 | Train Loss: 0.01365 | Valid Loss: 0.01664 | Time: 2.91 seconds\n",
      "Epoch: 351 | Train Loss: 0.01307 | Valid Loss: 0.01663 | Time: 2.87 seconds\n",
      "Epoch: 352 | Train Loss: 0.01342 | Valid Loss: 0.01691 | Time: 2.89 seconds\n",
      "Epoch: 353 | Train Loss: 0.01368 | Valid Loss: 0.01629 | Time: 3.15 seconds\n",
      "Epoch: 354 | Train Loss: 0.01340 | Valid Loss: 0.01666 | Time: 2.93 seconds\n",
      "Epoch: 355 | Train Loss: 0.01311 | Valid Loss: 0.01630 | Time: 2.86 seconds\n",
      "Epoch: 356 | Train Loss: 0.01245 | Valid Loss: 0.01659 | Time: 2.88 seconds\n",
      "Epoch: 357 | Train Loss: 0.01290 | Valid Loss: 0.01661 | Time: 2.88 seconds\n",
      "Epoch: 358 | Train Loss: 0.01289 | Valid Loss: 0.01637 | Time: 2.91 seconds\n",
      "Epoch: 359 | Train Loss: 0.01288 | Valid Loss: 0.01675 | Time: 2.86 seconds\n",
      "Epoch: 360 | Train Loss: 0.01313 | Valid Loss: 0.01660 | Time: 2.88 seconds\n",
      "Epoch: 361 | Train Loss: 0.01270 | Valid Loss: 0.01648 | Time: 2.88 seconds\n",
      "Epoch: 362 | Train Loss: 0.01318 | Valid Loss: 0.01650 | Time: 2.92 seconds\n",
      "Epoch: 363 | Train Loss: 0.01325 | Valid Loss: 0.01665 | Time: 2.87 seconds\n",
      "Epoch: 364 | Train Loss: 0.01325 | Valid Loss: 0.01673 | Time: 2.97 seconds\n",
      "Epoch: 365 | Train Loss: 0.01310 | Valid Loss: 0.01649 | Time: 2.91 seconds\n",
      "Epoch: 366 | Train Loss: 0.01233 | Valid Loss: 0.01688 | Time: 2.95 seconds\n",
      "Epoch: 367 | Train Loss: 0.01270 | Valid Loss: 0.01719 | Time: 2.87 seconds\n",
      "Epoch: 368 | Train Loss: 0.01297 | Valid Loss: 0.01630 | Time: 2.87 seconds\n",
      "Epoch: 369 | Train Loss: 0.01326 | Valid Loss: 0.01623 | Time: 3.17 seconds\n",
      "Epoch: 370 | Train Loss: 0.01264 | Valid Loss: 0.01648 | Time: 2.89 seconds\n",
      "Epoch: 371 | Train Loss: 0.01259 | Valid Loss: 0.01674 | Time: 2.88 seconds\n",
      "Epoch: 372 | Train Loss: 0.01391 | Valid Loss: 0.01639 | Time: 2.88 seconds\n",
      "Epoch: 373 | Train Loss: 0.01294 | Valid Loss: 0.01640 | Time: 2.94 seconds\n",
      "Epoch: 374 | Train Loss: 0.01298 | Valid Loss: 0.01626 | Time: 2.87 seconds\n",
      "Epoch: 375 | Train Loss: 0.01291 | Valid Loss: 0.01639 | Time: 2.95 seconds\n",
      "Epoch: 376 | Train Loss: 0.01317 | Valid Loss: 0.01683 | Time: 2.86 seconds\n",
      "Epoch: 377 | Train Loss: 0.01267 | Valid Loss: 0.01637 | Time: 2.91 seconds\n",
      "Epoch: 378 | Train Loss: 0.01274 | Valid Loss: 0.01663 | Time: 2.87 seconds\n",
      "Epoch: 379 | Train Loss: 0.01320 | Valid Loss: 0.01648 | Time: 2.86 seconds\n",
      "Epoch: 380 | Train Loss: 0.01245 | Valid Loss: 0.01660 | Time: 2.87 seconds\n",
      "Epoch: 381 | Train Loss: 0.01254 | Valid Loss: 0.01678 | Time: 2.92 seconds\n",
      "Epoch: 382 | Train Loss: 0.01326 | Valid Loss: 0.01691 | Time: 2.87 seconds\n",
      "Epoch: 383 | Train Loss: 0.01222 | Valid Loss: 0.01646 | Time: 2.87 seconds\n",
      "Epoch: 384 | Train Loss: 0.01331 | Valid Loss: 0.01664 | Time: 2.92 seconds\n",
      "Epoch: 385 | Train Loss: 0.01303 | Valid Loss: 0.01618 | Time: 3.14 seconds\n",
      "Epoch: 386 | Train Loss: 0.01265 | Valid Loss: 0.01642 | Time: 2.88 seconds\n",
      "Epoch: 387 | Train Loss: 0.01294 | Valid Loss: 0.01687 | Time: 2.89 seconds\n",
      "Epoch: 388 | Train Loss: 0.01266 | Valid Loss: 0.01622 | Time: 2.99 seconds\n",
      "Epoch: 389 | Train Loss: 0.01215 | Valid Loss: 0.01649 | Time: 2.87 seconds\n",
      "Epoch: 390 | Train Loss: 0.01282 | Valid Loss: 0.01669 | Time: 2.86 seconds\n",
      "Epoch: 391 | Train Loss: 0.01263 | Valid Loss: 0.01632 | Time: 2.86 seconds\n",
      "Epoch: 392 | Train Loss: 0.01259 | Valid Loss: 0.01654 | Time: 2.92 seconds\n",
      "Epoch: 393 | Train Loss: 0.01240 | Valid Loss: 0.01641 | Time: 2.89 seconds\n",
      "Epoch: 394 | Train Loss: 0.01233 | Valid Loss: 0.01657 | Time: 2.88 seconds\n",
      "Epoch: 395 | Train Loss: 0.01300 | Valid Loss: 0.01636 | Time: 2.88 seconds\n",
      "Epoch: 396 | Train Loss: 0.01243 | Valid Loss: 0.01627 | Time: 2.94 seconds\n",
      "Epoch: 397 | Train Loss: 0.01262 | Valid Loss: 0.01662 | Time: 2.88 seconds\n",
      "Epoch: 398 | Train Loss: 0.01285 | Valid Loss: 0.01653 | Time: 2.88 seconds\n",
      "Epoch: 399 | Train Loss: 0.01222 | Valid Loss: 0.01646 | Time: 2.98 seconds\n",
      "Epoch: 400 | Train Loss: 0.01245 | Valid Loss: 0.01636 | Time: 2.93 seconds\n",
      "Epoch: 401 | Train Loss: 0.01221 | Valid Loss: 0.01633 | Time: 2.87 seconds\n",
      "Epoch: 402 | Train Loss: 0.01274 | Valid Loss: 0.01624 | Time: 2.88 seconds\n",
      "Epoch: 403 | Train Loss: 0.01256 | Valid Loss: 0.01660 | Time: 2.92 seconds\n",
      "Epoch: 404 | Train Loss: 0.01281 | Valid Loss: 0.01654 | Time: 2.88 seconds\n",
      "Epoch: 405 | Train Loss: 0.01243 | Valid Loss: 0.01668 | Time: 2.87 seconds\n",
      "Epoch: 406 | Train Loss: 0.01231 | Valid Loss: 0.01634 | Time: 2.89 seconds\n",
      "Epoch: 407 | Train Loss: 0.01291 | Valid Loss: 0.01671 | Time: 2.91 seconds\n",
      "Epoch: 408 | Train Loss: 0.01202 | Valid Loss: 0.01643 | Time: 2.87 seconds\n",
      "Epoch: 409 | Train Loss: 0.01307 | Valid Loss: 0.01630 | Time: 2.86 seconds\n",
      "Epoch: 410 | Train Loss: 0.01211 | Valid Loss: 0.01668 | Time: 2.87 seconds\n",
      "Epoch: 411 | Train Loss: 0.01326 | Valid Loss: 0.01682 | Time: 3.16 seconds\n",
      "Epoch: 412 | Train Loss: 0.01259 | Valid Loss: 0.01660 | Time: 2.86 seconds\n",
      "Epoch: 413 | Train Loss: 0.01241 | Valid Loss: 0.01653 | Time: 2.88 seconds\n",
      "Epoch: 414 | Train Loss: 0.01246 | Valid Loss: 0.01680 | Time: 2.88 seconds\n",
      "Epoch: 415 | Train Loss: 0.01388 | Valid Loss: 0.01628 | Time: 2.93 seconds\n",
      "Epoch: 416 | Train Loss: 0.01203 | Valid Loss: 0.01671 | Time: 2.87 seconds\n",
      "Epoch: 417 | Train Loss: 0.01266 | Valid Loss: 0.01647 | Time: 2.87 seconds\n",
      "Epoch: 418 | Train Loss: 0.01284 | Valid Loss: 0.01654 | Time: 2.90 seconds\n",
      "Epoch: 419 | Train Loss: 0.01258 | Valid Loss: 0.01650 | Time: 2.91 seconds\n",
      "Epoch: 420 | Train Loss: 0.01295 | Valid Loss: 0.01682 | Time: 2.88 seconds\n",
      "Epoch: 421 | Train Loss: 0.01197 | Valid Loss: 0.01657 | Time: 2.87 seconds\n",
      "Epoch: 422 | Train Loss: 0.01212 | Valid Loss: 0.01670 | Time: 2.92 seconds\n",
      "Epoch: 423 | Train Loss: 0.01307 | Valid Loss: 0.01681 | Time: 3.04 seconds\n",
      "Epoch: 424 | Train Loss: 0.01251 | Valid Loss: 0.01632 | Time: 2.89 seconds\n",
      "Epoch: 425 | Train Loss: 0.01223 | Valid Loss: 0.01627 | Time: 2.87 seconds\n",
      "Epoch: 426 | Train Loss: 0.01172 | Valid Loss: 0.01620 | Time: 2.94 seconds\n",
      "Epoch: 427 | Train Loss: 0.01176 | Valid Loss: 0.01635 | Time: 2.88 seconds\n",
      "Epoch: 428 | Train Loss: 0.01224 | Valid Loss: 0.01615 | Time: 3.13 seconds\n",
      "Epoch: 429 | Train Loss: 0.01190 | Valid Loss: 0.01619 | Time: 2.87 seconds\n",
      "Epoch: 430 | Train Loss: 0.01248 | Valid Loss: 0.01643 | Time: 2.93 seconds\n",
      "Epoch: 431 | Train Loss: 0.01216 | Valid Loss: 0.01645 | Time: 2.87 seconds\n",
      "Epoch: 432 | Train Loss: 0.01189 | Valid Loss: 0.01667 | Time: 2.86 seconds\n",
      "Epoch: 433 | Train Loss: 0.01174 | Valid Loss: 0.01654 | Time: 2.89 seconds\n",
      "Epoch: 434 | Train Loss: 0.01211 | Valid Loss: 0.01638 | Time: 3.15 seconds\n",
      "Epoch: 435 | Train Loss: 0.01208 | Valid Loss: 0.01624 | Time: 2.88 seconds\n",
      "Epoch: 436 | Train Loss: 0.01203 | Valid Loss: 0.01681 | Time: 2.87 seconds\n",
      "Epoch: 437 | Train Loss: 0.01235 | Valid Loss: 0.01651 | Time: 2.96 seconds\n",
      "Epoch: 438 | Train Loss: 0.01185 | Valid Loss: 0.01655 | Time: 2.87 seconds\n",
      "Epoch: 439 | Train Loss: 0.01226 | Valid Loss: 0.01633 | Time: 2.87 seconds\n",
      "Epoch: 440 | Train Loss: 0.01234 | Valid Loss: 0.01659 | Time: 2.87 seconds\n",
      "Epoch: 441 | Train Loss: 0.01189 | Valid Loss: 0.01649 | Time: 2.92 seconds\n",
      "Epoch: 442 | Train Loss: 0.01274 | Valid Loss: 0.01658 | Time: 2.88 seconds\n",
      "Epoch: 443 | Train Loss: 0.01137 | Valid Loss: 0.01652 | Time: 2.87 seconds\n",
      "Epoch: 444 | Train Loss: 0.01213 | Valid Loss: 0.01661 | Time: 2.88 seconds\n",
      "Epoch: 445 | Train Loss: 0.01166 | Valid Loss: 0.01661 | Time: 3.14 seconds\n",
      "Epoch: 446 | Train Loss: 0.01230 | Valid Loss: 0.01641 | Time: 2.87 seconds\n",
      "Epoch: 447 | Train Loss: 0.01202 | Valid Loss: 0.01646 | Time: 2.88 seconds\n",
      "Epoch: 448 | Train Loss: 0.01141 | Valid Loss: 0.01614 | Time: 3.20 seconds\n",
      "Epoch: 449 | Train Loss: 0.01206 | Valid Loss: 0.01649 | Time: 2.91 seconds\n",
      "Epoch: 450 | Train Loss: 0.01211 | Valid Loss: 0.01655 | Time: 2.86 seconds\n",
      "Epoch: 451 | Train Loss: 0.01207 | Valid Loss: 0.01607 | Time: 3.13 seconds\n",
      "Epoch: 452 | Train Loss: 0.01165 | Valid Loss: 0.01662 | Time: 2.94 seconds\n",
      "Epoch: 453 | Train Loss: 0.01243 | Valid Loss: 0.01625 | Time: 2.88 seconds\n",
      "Epoch: 454 | Train Loss: 0.01194 | Valid Loss: 0.01621 | Time: 2.87 seconds\n",
      "Epoch: 455 | Train Loss: 0.01212 | Valid Loss: 0.01609 | Time: 2.88 seconds\n",
      "Epoch: 456 | Train Loss: 0.01133 | Valid Loss: 0.01646 | Time: 3.17 seconds\n",
      "Epoch: 457 | Train Loss: 0.01121 | Valid Loss: 0.01629 | Time: 2.88 seconds\n",
      "Epoch: 458 | Train Loss: 0.01200 | Valid Loss: 0.01625 | Time: 2.86 seconds\n",
      "Epoch: 459 | Train Loss: 0.01154 | Valid Loss: 0.01627 | Time: 2.87 seconds\n",
      "Epoch: 460 | Train Loss: 0.01151 | Valid Loss: 0.01648 | Time: 2.91 seconds\n",
      "Epoch: 461 | Train Loss: 0.01218 | Valid Loss: 0.01670 | Time: 2.86 seconds\n",
      "Epoch: 462 | Train Loss: 0.01219 | Valid Loss: 0.01643 | Time: 2.87 seconds\n",
      "Epoch: 463 | Train Loss: 0.01222 | Valid Loss: 0.01647 | Time: 2.87 seconds\n",
      "Epoch: 464 | Train Loss: 0.01181 | Valid Loss: 0.01655 | Time: 2.94 seconds\n",
      "Epoch: 465 | Train Loss: 0.01181 | Valid Loss: 0.01639 | Time: 2.88 seconds\n",
      "Epoch: 466 | Train Loss: 0.01185 | Valid Loss: 0.01625 | Time: 2.87 seconds\n",
      "Epoch: 467 | Train Loss: 0.01177 | Valid Loss: 0.01652 | Time: 3.11 seconds\n",
      "Epoch: 468 | Train Loss: 0.01169 | Valid Loss: 0.01660 | Time: 2.88 seconds\n",
      "Epoch: 469 | Train Loss: 0.01154 | Valid Loss: 0.01654 | Time: 2.88 seconds\n",
      "Epoch: 470 | Train Loss: 0.01149 | Valid Loss: 0.01640 | Time: 2.87 seconds\n",
      "Epoch: 471 | Train Loss: 0.01164 | Valid Loss: 0.01635 | Time: 2.93 seconds\n",
      "Epoch: 472 | Train Loss: 0.01159 | Valid Loss: 0.01633 | Time: 2.87 seconds\n",
      "Epoch: 473 | Train Loss: 0.01166 | Valid Loss: 0.01631 | Time: 2.88 seconds\n",
      "Epoch: 474 | Train Loss: 0.01137 | Valid Loss: 0.01646 | Time: 2.87 seconds\n",
      "Epoch: 475 | Train Loss: 0.01185 | Valid Loss: 0.01639 | Time: 2.92 seconds\n",
      "Epoch: 476 | Train Loss: 0.01173 | Valid Loss: 0.01604 | Time: 3.14 seconds\n",
      "Epoch: 477 | Train Loss: 0.01163 | Valid Loss: 0.01660 | Time: 2.87 seconds\n",
      "Epoch: 478 | Train Loss: 0.01228 | Valid Loss: 0.01637 | Time: 2.93 seconds\n",
      "Epoch: 479 | Train Loss: 0.01188 | Valid Loss: 0.01642 | Time: 3.02 seconds\n",
      "Epoch: 480 | Train Loss: 0.01172 | Valid Loss: 0.01649 | Time: 2.87 seconds\n",
      "Epoch: 481 | Train Loss: 0.01170 | Valid Loss: 0.01651 | Time: 2.86 seconds\n",
      "Epoch: 482 | Train Loss: 0.01141 | Valid Loss: 0.01639 | Time: 2.91 seconds\n",
      "Epoch: 483 | Train Loss: 0.01103 | Valid Loss: 0.01710 | Time: 2.88 seconds\n",
      "Epoch: 484 | Train Loss: 0.01170 | Valid Loss: 0.01626 | Time: 2.85 seconds\n",
      "Epoch: 485 | Train Loss: 0.01167 | Valid Loss: 0.01694 | Time: 2.86 seconds\n",
      "Epoch: 486 | Train Loss: 0.01160 | Valid Loss: 0.01638 | Time: 2.89 seconds\n",
      "Epoch: 487 | Train Loss: 0.01152 | Valid Loss: 0.01622 | Time: 2.86 seconds\n",
      "Epoch: 488 | Train Loss: 0.01191 | Valid Loss: 0.01659 | Time: 2.87 seconds\n",
      "Epoch: 489 | Train Loss: 0.01191 | Valid Loss: 0.01664 | Time: 2.88 seconds\n",
      "Epoch: 490 | Train Loss: 0.01173 | Valid Loss: 0.01637 | Time: 3.17 seconds\n",
      "Epoch: 491 | Train Loss: 0.01174 | Valid Loss: 0.01647 | Time: 2.87 seconds\n",
      "Epoch: 492 | Train Loss: 0.01155 | Valid Loss: 0.01646 | Time: 2.87 seconds\n",
      "Epoch: 493 | Train Loss: 0.01211 | Valid Loss: 0.01666 | Time: 2.86 seconds\n",
      "Epoch: 494 | Train Loss: 0.01144 | Valid Loss: 0.01651 | Time: 2.94 seconds\n",
      "Epoch: 495 | Train Loss: 0.01115 | Valid Loss: 0.01621 | Time: 2.88 seconds\n",
      "Epoch: 496 | Train Loss: 0.01174 | Valid Loss: 0.01606 | Time: 2.89 seconds\n",
      "Epoch: 497 | Train Loss: 0.01156 | Valid Loss: 0.01649 | Time: 2.87 seconds\n",
      "Epoch: 498 | Train Loss: 0.01139 | Valid Loss: 0.01618 | Time: 2.93 seconds\n",
      "Epoch: 499 | Train Loss: 0.01170 | Valid Loss: 0.01618 | Time: 2.86 seconds\n",
      "Epoch: 500 | Train Loss: 0.01129 | Valid Loss: 0.01662 | Time: 2.87 seconds\n",
      "\n",
      "**************************************************\n",
      "\n",
      "Best Validation Loss at Epoch 476\n",
      "\n",
      "**************************************************\n",
      "\n",
      "Time Taken [500 Epochs] : 24.69 minutes\n",
      "\n",
      "**************************************************\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tr_idx, va_idx in KFold(n_splits=cfg.n_splits, random_state=cfg.seed, shuffle=True).split(images):\n",
    "    break\n",
    "\n",
    "tr_images, va_images, tr_bboxes, va_bboxes = images[tr_idx], images[va_idx], bboxes[tr_idx], bboxes[va_idx]\n",
    "\n",
    "tr_data_setup = DS(tr_images, tr_bboxes, cfg.transform)\n",
    "va_data_setup = DS(va_images, va_bboxes, cfg.transform)\n",
    "\n",
    "dataloaders = {\n",
    "    \"train\" : DL(tr_data_setup, batch_size=cfg.batch_size, shuffle=True, generator=torch.manual_seed(cfg.seed)),\n",
    "    \"valid\" : DL(va_data_setup, batch_size=cfg.batch_size, shuffle=False),\n",
    "}\n",
    "\n",
    "cfg = CFG(\n",
    "    seed=SEED, \n",
    "    size=SIZE, \n",
    "    epochs=500, \n",
    "    batch_size=64, \n",
    "    early_stopping=50, \n",
    "    lr=1e-5, \n",
    "    wd=1e-5, \n",
    "    steps_per_epoch=len(dataloaders[\"train\"])\n",
    ")\n",
    "\n",
    "torch.manual_seed(cfg.seed)\n",
    "model = Model().to(cfg.device)\n",
    "\n",
    "optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad], lr=cfg.lr, weight_decay=cfg.wd)\n",
    "# optimizer = optim.AdamW([p for p in model.parameters() if p.requires_grad], lr=cfg.lr, weight_decay=cfg.wd)\n",
    "\n",
    "# scheduler_oclr = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, \n",
    "#                                                max_lr=cfg.max_lr, \n",
    "#                                                epochs=cfg.epochs, \n",
    "#                                                steps_per_epoch=cfg.steps_per_epoch,\n",
    "#                                                pct_start=cfg.pct_start, \n",
    "#                                                div_factor=cfg.div_factor, \n",
    "#                                                final_div_factor=cfg.final_div_factor)\n",
    "# scheduler_rlrop = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "#                                                        patience=cfg.patience,\n",
    "#                                                        eps=cfg.eps,\n",
    "#                                                        verbose=True)\n",
    "\n",
    "scheduler_oclr = None\n",
    "scheduler_rlrop = None\n",
    "\n",
    "L, LRs, BLE, name = fit(model=model, \n",
    "                        optimizer=optimizer, \n",
    "                        scheduler_oclr=scheduler_oclr, \n",
    "                        scheduler_rlrop=scheduler_rlrop, \n",
    "                        epochs=cfg.epochs, \n",
    "                        early_stopping_patience=cfg.early_stopping, \n",
    "                        dataloaders=dataloaders, \n",
    "                        device=cfg.device,\n",
    "                        save_path=cfg.save_path,\n",
    "                        verbose=True)\n",
    "\n",
    "breaker()\n",
    "show_loss_graphs(L)\n",
    "breaker()\n",
    "\n",
    "if scheduler_oclr:\n",
    "    x_Axis = [i+1 for i in range(len(LRs))]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(x_Axis, LRs, \"rx\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    breaker()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1506.091934,
   "end_time": "2022-07-04T13:31:51.038891",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-04T13:06:44.946957",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0d829fcdcef34ee687469a57e2c0b542": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1bdea07c0b3e4cb29bbd7886268cf067",
       "max": 102530333.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c5f16e6741de4acca6ebafe6d5faae72",
       "value": 102530333.0
      }
     },
     "13bd94fb89d743a583bac79f9828b74f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1bdea07c0b3e4cb29bbd7886268cf067": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "357c2a3274894e97b4caa60d39628ae5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b7d006f639bf47ecbe29ca1a435e0304",
        "IPY_MODEL_0d829fcdcef34ee687469a57e2c0b542",
        "IPY_MODEL_5a97f925250c4f969fb7e15e24417036"
       ],
       "layout": "IPY_MODEL_f91629b2b297435ba7875da541604afb"
      }
     },
     "4d20fd202fe1409cbbc180cc939856bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5a97f925250c4f969fb7e15e24417036": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f5d7b872f4d8497bbe40580a53a363bf",
       "placeholder": "​",
       "style": "IPY_MODEL_ff5dc45e8c8e437bbcc9657815042e79",
       "value": " 97.8M/97.8M [00:05&lt;00:00, 23.4MB/s]"
      }
     },
     "b7d006f639bf47ecbe29ca1a435e0304": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_13bd94fb89d743a583bac79f9828b74f",
       "placeholder": "​",
       "style": "IPY_MODEL_4d20fd202fe1409cbbc180cc939856bd",
       "value": "100%"
      }
     },
     "c5f16e6741de4acca6ebafe6d5faae72": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f5d7b872f4d8497bbe40580a53a363bf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f91629b2b297435ba7875da541604afb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ff5dc45e8c8e437bbcc9657815042e79": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
