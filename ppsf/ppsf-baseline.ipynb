{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dd4fe2d",
   "metadata": {
    "papermill": {
     "duration": 0.003519,
     "end_time": "2022-09-07T12:04:52.776869",
     "exception": false,
     "start_time": "2022-09-07T12:04:52.773350",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Library Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56ff0059",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-09-07T12:04:52.784220Z",
     "iopub.status.busy": "2022-09-07T12:04:52.783797Z",
     "iopub.status.idle": "2022-09-07T12:04:54.192359Z",
     "shell.execute_reply": "2022-09-07T12:04:54.191122Z"
    },
    "papermill": {
     "duration": 1.415164,
     "end_time": "2022-09-07T12:04:54.194912",
     "exception": false,
     "start_time": "2022-09-07T12:04:52.779748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as r\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from time import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa298ef1",
   "metadata": {
    "papermill": {
     "duration": 0.002599,
     "end_time": "2022-09-07T12:04:54.200586",
     "exception": false,
     "start_time": "2022-09-07T12:04:54.197987",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1a77b35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-07T12:04:54.208372Z",
     "iopub.status.busy": "2022-09-07T12:04:54.207864Z",
     "iopub.status.idle": "2022-09-07T12:04:54.215248Z",
     "shell.execute_reply": "2022-09-07T12:04:54.214005Z"
    },
    "papermill": {
     "duration": 0.013959,
     "end_time": "2022-09-07T12:04:54.217605",
     "exception": false,
     "start_time": "2022-09-07T12:04:54.203646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG(object):\n",
    "    def __init__(self,\n",
    "                 seed: int = 42,\n",
    "                 n_splits: int = 5,\n",
    "                 show_info: bool = False,\n",
    "                 ):\n",
    "\n",
    "        self.seed = seed\n",
    "        self.n_splits = n_splits\n",
    "        self.show_info = show_info\n",
    "        self.train_data_read_path = \"../input/predict-potential-spammers-on-fiverr/train.csv\"\n",
    "        self.test_data_read_path = \"../input/predict-potential-spammers-on-fiverr/test.csv\"\n",
    "        self.ss_data_read_path = \"../input/predict-potential-spammers-on-fiverr/sample_submission.csv\"\n",
    "        self.model_save_path = \"models\"\n",
    "        if not os.path.exists(self.model_save_path): os.makedirs(self.model_save_path)\n",
    "\n",
    "cfg = CFG(seed=42, show_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f057d1cc",
   "metadata": {
    "papermill": {
     "duration": 0.002716,
     "end_time": "2022-09-07T12:04:54.223551",
     "exception": false,
     "start_time": "2022-09-07T12:04:54.220835",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Helpers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ece0ddd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-07T12:04:54.231535Z",
     "iopub.status.busy": "2022-09-07T12:04:54.230888Z",
     "iopub.status.idle": "2022-09-07T12:04:54.238992Z",
     "shell.execute_reply": "2022-09-07T12:04:54.238279Z"
    },
    "papermill": {
     "duration": 0.014886,
     "end_time": "2022-09-07T12:04:54.241344",
     "exception": false,
     "start_time": "2022-09-07T12:04:54.226458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def breaker(num: int=50, char: str=\"*\") -> None:\n",
    "    print(\"\\n\" + num*char + \"\\n\")\n",
    "\n",
    "    \n",
    "def get_object_columns(df) -> list:\n",
    "    object_columns: list = []\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == \"object\":\n",
    "            object_columns.append(col)\n",
    "\n",
    "    return object_columns\n",
    "    \n",
    "\n",
    "def print_scores(accuracy: float, auc: float, precision: np.ndarray, recall: np.ndarray, f_score: np.ndarray) -> None:\n",
    "    print(f\"Accuracy  : {accuracy:.5f}\")\n",
    "    print(f\"ROC-AUC   : {auc:.5f}\")\n",
    "    print(f\"Precision : {precision}\")\n",
    "    print(f\"Recall    : {recall}\")\n",
    "    print(f\"F-Score   : {f_score}\")\n",
    "    \n",
    "\n",
    "def get_scores(y_true: np.ndarray, y_pred: np.ndarray) -> tuple:\n",
    "    accuracy = accuracy_score(y_pred, y_true)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_pred, y_true)\n",
    "    except: \n",
    "        auc = 0.0\n",
    "    precision, recall, f_score, _ = precision_recall_fscore_support(y_pred, y_true)\n",
    "\n",
    "    return accuracy, auc, precision, recall, f_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff975ce",
   "metadata": {
    "papermill": {
     "duration": 0.002892,
     "end_time": "2022-09-07T12:04:54.247503",
     "exception": false,
     "start_time": "2022-09-07T12:04:54.244611",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02851f4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-07T12:04:54.255471Z",
     "iopub.status.busy": "2022-09-07T12:04:54.254835Z",
     "iopub.status.idle": "2022-09-07T12:04:54.266416Z",
     "shell.execute_reply": "2022-09-07T12:04:54.265669Z"
    },
    "papermill": {
     "duration": 0.01859,
     "end_time": "2022-09-07T12:04:54.269037",
     "exception": false,
     "start_time": "2022-09-07T12:04:54.250447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, model_name: str, preprocessor, seed: int):\n",
    "        self.model_name = model_name\n",
    "\n",
    "        if self.model_name == \"lgr\":\n",
    "            self.model = Pipeline(\n",
    "                steps=[\n",
    "                    (\"preprocessor\", preprocessor),\n",
    "                    (\"classifier\", LogisticRegression(random_state=seed)),\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "        elif self.model_name == \"knc\":\n",
    "            self.model = Pipeline(\n",
    "                steps=[\n",
    "                    (\"preprocessor\", preprocessor),\n",
    "                    (\"classifier\", KNeighborsClassifier()),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        \n",
    "        elif self.model_name == \"dtc\":\n",
    "            self.model = Pipeline(\n",
    "                steps=[\n",
    "                    (\"preprocessor\", preprocessor),\n",
    "                    (\"classifier\", DecisionTreeClassifier(random_state=seed)),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        elif self.model_name == \"etc\":\n",
    "            self.model = Pipeline(\n",
    "                steps=[\n",
    "                    (\"preprocessor\", preprocessor),\n",
    "                    (\"classifier\", ExtraTreeClassifier(random_state=seed)),\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "        elif self.model_name == \"rfc\":\n",
    "            self.model = Pipeline(\n",
    "                steps=[\n",
    "                    (\"preprocessor\", preprocessor),\n",
    "                    (\"classifier\", RandomForestClassifier(random_state=seed)),\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "        elif self.model_name == \"gbc\":\n",
    "            self.model = Pipeline(\n",
    "                steps=[\n",
    "                    (\"preprocessor\", preprocessor),\n",
    "                    (\"classifier\", GradientBoostingClassifier(random_state=seed)),\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "        elif self.model_name == \"abc\":\n",
    "            self.model = Pipeline(\n",
    "                steps=[\n",
    "                    (\"preprocessor\", preprocessor),\n",
    "                    (\"classifier\", AdaBoostClassifier(random_state=seed)),\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "        elif self.model_name == \"etcs\":\n",
    "            self.model = Pipeline(\n",
    "                steps=[\n",
    "                    (\"preprocessor\", preprocessor),\n",
    "                    (\"classifier\", ExtraTreesClassifier(random_state=seed)),\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "        elif self.model_name == \"gnb\":\n",
    "            self.model = Pipeline(\n",
    "                steps=[\n",
    "                    (\"preprocessor\", preprocessor),\n",
    "                    (\"classifier\", GaussianNB()),\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "        elif self.model_name == \"xgbc\":\n",
    "            self.model = Pipeline(\n",
    "                steps=[\n",
    "                    (\"preprocessor\", preprocessor),\n",
    "                    (\"classifier\", XGBClassifier(random_state=seed)),\n",
    "                ]\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf5fee9",
   "metadata": {
    "papermill": {
     "duration": 0.002786,
     "end_time": "2022-09-07T12:04:54.275082",
     "exception": false,
     "start_time": "2022-09-07T12:04:54.272296",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "489425d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-07T12:04:54.283059Z",
     "iopub.status.busy": "2022-09-07T12:04:54.282390Z",
     "iopub.status.idle": "2022-09-07T12:04:56.073241Z",
     "shell.execute_reply": "2022-09-07T12:04:56.071833Z"
    },
    "papermill": {
     "duration": 1.799024,
     "end_time": "2022-09-07T12:04:56.077055",
     "exception": false,
     "start_time": "2022-09-07T12:04:54.278031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************************************************\n",
      "\n",
      "Class 0 count : 446477\n",
      "Class 1 count : 12321\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(cfg.train_data_read_path)\n",
    "df = df.drop(columns=[\"user_id\"])\n",
    "object_columns = get_object_columns(df)\n",
    "df = df.drop(columns=object_columns)\n",
    "\n",
    "if cfg.show_info:\n",
    "    breaker()\n",
    "    for val in set(df.label):\n",
    "        print(f\"Class {val} count : {df[df.label == val].shape[0]}\")\n",
    "\n",
    "X = df.iloc[:, :-1].copy().values\n",
    "y = df.iloc[:, -1].copy().values\n",
    "\n",
    "features = [i for i in range(X.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb91587a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-07T12:04:56.085755Z",
     "iopub.status.busy": "2022-09-07T12:04:56.085356Z",
     "iopub.status.idle": "2022-09-07T13:01:45.469410Z",
     "shell.execute_reply": "2022-09-07T13:01:45.467782Z"
    },
    "papermill": {
     "duration": 3409.398144,
     "end_time": "2022-09-07T13:01:45.478999",
     "exception": false,
     "start_time": "2022-09-07T12:04:56.080855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgr, 1\n",
      "\n",
      "Accuracy  : 0.99990\n",
      "ROC-AUC   : 0.00000\n",
      "Precision : [1. 0.]\n",
      "Recall    : [0.99990192 0.        ]\n",
      "F-Score   : [0.99995096 0.        ]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgr, 2\n",
      "\n",
      "Accuracy  : 0.99991\n",
      "ROC-AUC   : 0.00000\n",
      "Precision : [1. 0.]\n",
      "Recall    : [0.99991282 0.        ]\n",
      "F-Score   : [0.99995641 0.        ]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgr, 3\n",
      "\n",
      "Accuracy  : 0.99992\n",
      "ROC-AUC   : 0.00000\n",
      "Precision : [1. 0.]\n",
      "Recall    : [0.99992371 0.        ]\n",
      "F-Score   : [0.99996186 0.        ]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgr, 4\n",
      "\n",
      "Accuracy  : 0.99995\n",
      "ROC-AUC   : 0.00000\n",
      "Precision : [1. 0.]\n",
      "Recall    : [0.99994551 0.        ]\n",
      "F-Score   : [0.99997275 0.        ]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgr, 5\n",
      "\n",
      "Accuracy  : 0.99996\n",
      "ROC-AUC   : 0.00000\n",
      "Precision : [1. 0.]\n",
      "Recall    : [0.99995641 0.        ]\n",
      "F-Score   : [0.9999782 0.       ]\n",
      "\n",
      "\n",
      "**************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knc, 1\n",
      "\n",
      "Accuracy  : 0.99990\n",
      "ROC-AUC   : 0.00000\n",
      "Precision : [1. 0.]\n",
      "Recall    : [0.99990192 0.        ]\n",
      "F-Score   : [0.99995096 0.        ]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knc, 2\n",
      "\n",
      "Accuracy  : 0.99991\n",
      "ROC-AUC   : 0.00000\n",
      "Precision : [1. 0.]\n",
      "Recall    : [0.99991282 0.        ]\n",
      "F-Score   : [0.99995641 0.        ]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knc, 3\n",
      "\n",
      "Accuracy  : 0.99992\n",
      "ROC-AUC   : 0.00000\n",
      "Precision : [1. 0.]\n",
      "Recall    : [0.99992371 0.        ]\n",
      "F-Score   : [0.99996186 0.        ]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knc, 4\n",
      "\n",
      "Accuracy  : 0.99995\n",
      "ROC-AUC   : 0.00000\n",
      "Precision : [1. 0.]\n",
      "Recall    : [0.99994551 0.        ]\n",
      "F-Score   : [0.99997275 0.        ]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knc, 5\n",
      "\n",
      "Accuracy  : 0.99996\n",
      "ROC-AUC   : 0.00000\n",
      "Precision : [1. 0.]\n",
      "Recall    : [0.99995641 0.        ]\n",
      "F-Score   : [0.9999782 0.       ]\n",
      "\n",
      "\n",
      "**************************************************\n",
      "\n",
      "gnb, 1\n",
      "\n",
      "Accuracy  : 0.52245\n",
      "ROC-AUC   : 0.50010\n",
      "Precision : [0.52240303 1.        ]\n",
      "Recall    : [1.00000000e+00 2.05343494e-04]\n",
      "F-Score   : [6.86287424e-01 4.10602673e-04]\n",
      "\n",
      "gnb, 2\n",
      "\n",
      "Accuracy  : 0.51372\n",
      "ROC-AUC   : 0.50009\n",
      "Precision : [0.51367818 1.        ]\n",
      "Recall    : [1.00000000e+00 1.79255641e-04]\n",
      "F-Score   : [6.78715178e-01 3.58447028e-04]\n",
      "\n",
      "gnb, 3\n",
      "\n",
      "Accuracy  : 0.51311\n",
      "ROC-AUC   : 0.50008\n",
      "Precision : [0.51307314 1.        ]\n",
      "Recall    : [1.00000000e+00 1.56655626e-04]\n",
      "F-Score   : [6.78186834e-01 3.13262178e-04]\n",
      "\n",
      "gnb, 4\n",
      "\n",
      "Accuracy  : 0.53875\n",
      "ROC-AUC   : 0.50004\n",
      "Precision : [0.53873401 0.8       ]\n",
      "Recall    : [9.99979770e-01 9.45023271e-05]\n",
      "F-Score   : [7.00225235e-01 1.88982330e-04]\n",
      "\n",
      "gnb, 5\n",
      "\n",
      "Accuracy  : 0.52747\n",
      "ROC-AUC   : 0.50002\n",
      "Precision : [0.52745899 0.75      ]\n",
      "Recall    : [9.99979338e-01 6.91865963e-05]\n",
      "F-Score   : [6.90630953e-01 1.38360429e-04]\n",
      "\n",
      "\n",
      "**************************************************\n",
      "\n",
      "dtc, 1\n",
      "\n",
      "Accuracy  : 0.99978\n",
      "ROC-AUC   : 0.49995\n",
      "Precision : [0.99988011 0.        ]\n",
      "Recall    : [0.99990191 0.        ]\n",
      "F-Score   : [0.99989101 0.        ]\n",
      "\n",
      "dtc, 2\n",
      "\n",
      "Accuracy  : 0.99979\n",
      "ROC-AUC   : 0.49996\n",
      "Precision : [0.99988011 0.        ]\n",
      "Recall    : [0.99991281 0.        ]\n",
      "F-Score   : [0.99989646 0.        ]\n",
      "\n",
      "dtc, 3\n",
      "\n",
      "Accuracy  : 0.99980\n",
      "ROC-AUC   : 0.49996\n",
      "Precision : [0.99988011 0.        ]\n",
      "Recall    : [0.9999237 0.       ]\n",
      "F-Score   : [0.99990191 0.        ]\n",
      "\n",
      "dtc, 4\n",
      "\n",
      "Accuracy  : 0.99989\n",
      "ROC-AUC   : 0.49997\n",
      "Precision : [0.99994551 0.        ]\n",
      "Recall    : [0.99994551 0.        ]\n",
      "F-Score   : [0.99994551 0.        ]\n",
      "\n",
      "dtc, 5\n",
      "\n",
      "Accuracy  : 0.99985\n",
      "ROC-AUC   : 0.49998\n",
      "Precision : [0.99989101 0.        ]\n",
      "Recall    : [0.9999564 0.       ]\n",
      "F-Score   : [0.99992371 0.        ]\n",
      "\n",
      "\n",
      "**************************************************\n",
      "\n",
      "etc, 1\n",
      "\n",
      "Accuracy  : 0.99979\n",
      "ROC-AUC   : 0.49995\n",
      "Precision : [0.99989101 0.        ]\n",
      "Recall    : [0.99990191 0.        ]\n",
      "F-Score   : [0.99989646 0.        ]\n",
      "\n",
      "etc, 2\n",
      "\n",
      "Accuracy  : 0.99988\n",
      "ROC-AUC   : 0.49996\n",
      "Precision : [0.9999673 0.       ]\n",
      "Recall    : [0.99991281 0.        ]\n",
      "F-Score   : [0.99994006 0.        ]\n",
      "\n",
      "etc, 3\n",
      "\n",
      "Accuracy  : 0.99985\n",
      "ROC-AUC   : 0.49996\n",
      "Precision : [0.99992371 0.        ]\n",
      "Recall    : [0.99992371 0.        ]\n",
      "F-Score   : [0.99992371 0.        ]\n",
      "\n",
      "etc, 4\n",
      "\n",
      "Accuracy  : 0.99984\n",
      "ROC-AUC   : 0.49997\n",
      "Precision : [0.99989101 0.        ]\n",
      "Recall    : [0.9999455 0.       ]\n",
      "F-Score   : [0.99991826 0.        ]\n",
      "\n",
      "etc, 5\n",
      "\n",
      "Accuracy  : 0.99988\n",
      "ROC-AUC   : 0.49998\n",
      "Precision : [0.99992371 0.        ]\n",
      "Recall    : [0.9999564 0.       ]\n",
      "F-Score   : [0.99994006 0.        ]\n",
      "\n",
      "\n",
      "**************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc, 1\n",
      "\n",
      "Accuracy  : 0.99990\n",
      "ROC-AUC   : 0.00000\n",
      "Precision : [1. 0.]\n",
      "Recall    : [0.99990192 0.        ]\n",
      "F-Score   : [0.99995096 0.        ]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc, 2\n",
      "\n",
      "Accuracy  : 0.99991\n",
      "ROC-AUC   : 0.00000\n",
      "Precision : [1. 0.]\n",
      "Recall    : [0.99991282 0.        ]\n",
      "F-Score   : [0.99995641 0.        ]\n",
      "\n",
      "abc, 3\n",
      "\n",
      "Accuracy  : 0.99990\n",
      "ROC-AUC   : 0.49996\n",
      "Precision : [0.9999782 0.       ]\n",
      "Recall    : [0.99992371 0.        ]\n",
      "F-Score   : [0.99995096 0.        ]\n",
      "\n",
      "abc, 4\n",
      "\n",
      "Accuracy  : 0.99993\n",
      "ROC-AUC   : 0.49997\n",
      "Precision : [0.9999891 0.       ]\n",
      "Recall    : [0.99994551 0.        ]\n",
      "F-Score   : [0.9999673 0.       ]\n",
      "\n",
      "abc, 5\n",
      "\n",
      "Accuracy  : 0.99995\n",
      "ROC-AUC   : 0.49998\n",
      "Precision : [0.9999891 0.       ]\n",
      "Recall    : [0.99995641 0.        ]\n",
      "F-Score   : [0.99997275 0.        ]\n",
      "\n",
      "\n",
      "**************************************************\n",
      "\n",
      "gbc, 1\n",
      "\n",
      "Accuracy  : 0.99979\n",
      "ROC-AUC   : 0.49995\n",
      "Precision : [0.99989101 0.        ]\n",
      "Recall    : [0.99990191 0.        ]\n",
      "F-Score   : [0.99989646 0.        ]\n",
      "\n",
      "gbc, 2\n",
      "\n",
      "Accuracy  : 0.99990\n",
      "ROC-AUC   : 0.49996\n",
      "Precision : [0.9999891 0.       ]\n",
      "Recall    : [0.99991282 0.        ]\n",
      "F-Score   : [0.99995096 0.        ]\n",
      "\n",
      "gbc, 3\n",
      "\n",
      "Accuracy  : 0.99991\n",
      "ROC-AUC   : 0.49996\n",
      "Precision : [0.9999891 0.       ]\n",
      "Recall    : [0.99992371 0.        ]\n",
      "F-Score   : [0.99995641 0.        ]\n",
      "\n",
      "gbc, 4\n",
      "\n",
      "Accuracy  : 0.99992\n",
      "ROC-AUC   : 0.49997\n",
      "Precision : [0.9999782 0.       ]\n",
      "Recall    : [0.99994551 0.        ]\n",
      "F-Score   : [0.99996186 0.        ]\n",
      "\n",
      "gbc, 5\n",
      "\n",
      "Accuracy  : 0.99987\n",
      "ROC-AUC   : 0.49998\n",
      "Precision : [0.99991281 0.        ]\n",
      "Recall    : [0.9999564 0.       ]\n",
      "F-Score   : [0.99993461 0.        ]\n",
      "\n",
      "\n",
      "**************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etcs, 1\n",
      "\n",
      "Accuracy  : 0.99990\n",
      "ROC-AUC   : 0.00000\n",
      "Precision : [1. 0.]\n",
      "Recall    : [0.99990192 0.        ]\n",
      "F-Score   : [0.99995096 0.        ]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etcs, 2\n",
      "\n",
      "Accuracy  : 0.99991\n",
      "ROC-AUC   : 0.00000\n",
      "Precision : [1. 0.]\n",
      "Recall    : [0.99991282 0.        ]\n",
      "F-Score   : [0.99995641 0.        ]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etcs, 3\n",
      "\n",
      "Accuracy  : 0.99992\n",
      "ROC-AUC   : 0.00000\n",
      "Precision : [1. 0.]\n",
      "Recall    : [0.99992371 0.        ]\n",
      "F-Score   : [0.99996186 0.        ]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etcs, 4\n",
      "\n",
      "Accuracy  : 0.99995\n",
      "ROC-AUC   : 0.00000\n",
      "Precision : [1. 0.]\n",
      "Recall    : [0.99994551 0.        ]\n",
      "F-Score   : [0.99997275 0.        ]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etcs, 5\n",
      "\n",
      "Accuracy  : 0.99996\n",
      "ROC-AUC   : 0.00000\n",
      "Precision : [1. 0.]\n",
      "Recall    : [0.99995641 0.        ]\n",
      "F-Score   : [0.9999782 0.       ]\n",
      "\n",
      "\n",
      "**************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc, 1\n",
      "\n",
      "Accuracy  : 0.99990\n",
      "ROC-AUC   : 0.00000\n",
      "Precision : [1. 0.]\n",
      "Recall    : [0.99990192 0.        ]\n",
      "F-Score   : [0.99995096 0.        ]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc, 2\n",
      "\n",
      "Accuracy  : 0.99991\n",
      "ROC-AUC   : 0.00000\n",
      "Precision : [1. 0.]\n",
      "Recall    : [0.99991282 0.        ]\n",
      "F-Score   : [0.99995641 0.        ]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc, 3\n",
      "\n",
      "Accuracy  : 0.99992\n",
      "ROC-AUC   : 0.00000\n",
      "Precision : [1. 0.]\n",
      "Recall    : [0.99992371 0.        ]\n",
      "F-Score   : [0.99996186 0.        ]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc, 4\n",
      "\n",
      "Accuracy  : 0.99995\n",
      "ROC-AUC   : 0.00000\n",
      "Precision : [1. 0.]\n",
      "Recall    : [0.99994551 0.        ]\n",
      "F-Score   : [0.99997275 0.        ]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc, 5\n",
      "\n",
      "Accuracy  : 0.99996\n",
      "ROC-AUC   : 0.00000\n",
      "Precision : [1. 0.]\n",
      "Recall    : [0.99995641 0.        ]\n",
      "F-Score   : [0.9999782 0.       ]\n",
      "\n",
      "\n",
      "**************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgbc, 1\n",
      "\n",
      "Accuracy  : 0.99990\n",
      "ROC-AUC   : 0.00000\n",
      "Precision : [1. 0.]\n",
      "Recall    : [0.99990192 0.        ]\n",
      "F-Score   : [0.99995096 0.        ]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgbc, 2\n",
      "\n",
      "Accuracy  : 0.99991\n",
      "ROC-AUC   : 0.00000\n",
      "Precision : [1. 0.]\n",
      "Recall    : [0.99991282 0.        ]\n",
      "F-Score   : [0.99995641 0.        ]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgbc, 3\n",
      "\n",
      "Accuracy  : 0.99992\n",
      "ROC-AUC   : 0.00000\n",
      "Precision : [1. 0.]\n",
      "Recall    : [0.99992371 0.        ]\n",
      "F-Score   : [0.99996186 0.        ]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgbc, 4\n",
      "\n",
      "Accuracy  : 0.99995\n",
      "ROC-AUC   : 0.00000\n",
      "Precision : [1. 0.]\n",
      "Recall    : [0.99994551 0.        ]\n",
      "F-Score   : [0.99997275 0.        ]\n",
      "\n",
      "xgbc, 5\n",
      "\n",
      "Accuracy  : 0.99996\n",
      "ROC-AUC   : 0.00000\n",
      "Precision : [1. 0.]\n",
      "Recall    : [0.99995641 0.        ]\n",
      "F-Score   : [0.9999782 0.       ]\n",
      "\n",
      "\n",
      "**************************************************\n",
      "\n",
      "Best Model : lgr, Best Fold : 5\n",
      "\n",
      "**************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "names: list = [\"lgr\", \"knc\", \"gnb\", \"dtc\", \"etc\", \"abc\", \"gbc\", \"etcs\", \"rfc\", \"xgbc\"]\n",
    "# names: list = [\"lgr\"]\n",
    "\n",
    "feature_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"Simple_Imputer\", SimpleImputer(missing_values=np.nan, strategy=\"mean\")),\n",
    "        (\"Standard_Scaler\", StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"features\", feature_transformer, features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "best_acc: float = 0.0\n",
    "for name in names:\n",
    "    fold = 1\n",
    "    if cfg.show_info: breaker()\n",
    "    for tr_idx, va_idx in KFold(n_splits=cfg.n_splits, random_state=cfg.seed, shuffle=True).split(X):\n",
    "        X_train, X_valid, y_train, y_valid = X[tr_idx], X[va_idx], y[tr_idx], y[va_idx]\n",
    "        my_pipeline = Model(name, preprocessor, cfg.seed)\n",
    "        my_pipeline.model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = my_pipeline.model.predict(X_valid)\n",
    "        if cfg.show_info:\n",
    "            acc, auc, pre, rec, f1 = get_scores(y_valid, y_pred)\n",
    "            print(f\"{my_pipeline.model_name}, {fold}\\n\")\n",
    "            print_scores(acc, auc, pre, rec, f1)\n",
    "            print(\"\")\n",
    "        else:\n",
    "            _, auc, _, _, _ = get_scores(y_valid, y_pred)\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            model_fold_name = f\"{name}_{fold}\"\n",
    "            \n",
    "            with open(os.path.join(cfg.model_save_path, f\"best_model.pkl\"), \"wb\") as fp:\n",
    "                pickle.dump(my_pipeline.model, fp)\n",
    "        fold += 1\n",
    "    \n",
    "\n",
    "if cfg.show_info: \n",
    "    breaker()\n",
    "    print(f\"Best Model : {model_fold_name.split('_')[0]}, Best Fold : {model_fold_name.split('_')[1]}\")\n",
    "\n",
    "breaker()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3b67ca",
   "metadata": {
    "papermill": {
     "duration": 0.007476,
     "end_time": "2022-09-07T13:01:45.494226",
     "exception": false,
     "start_time": "2022-09-07T13:01:45.486750",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a7f18d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-07T13:01:45.511436Z",
     "iopub.status.busy": "2022-09-07T13:01:45.510822Z",
     "iopub.status.idle": "2022-09-07T13:01:45.681884Z",
     "shell.execute_reply": "2022-09-07T13:01:45.680937Z"
    },
    "papermill": {
     "duration": 0.183614,
     "end_time": "2022-09-07T13:01:45.685436",
     "exception": false,
     "start_time": "2022-09-07T13:01:45.501822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(cfg.test_data_read_path)\n",
    "df = df.drop(columns=[\"user_id\"])\n",
    "\n",
    "X = df.copy().values\n",
    "\n",
    "model = pickle.load(open(os.path.join(cfg.model_save_path, f\"best_model.pkl\"), \"rb\"))\n",
    "y_pred = model.predict_proba(X)[:, 1]\n",
    "\n",
    "ss_df = pd.read_csv(cfg.ss_data_read_path)\n",
    "ss_df[\"label\"] = y_pred.astype(\"uint8\")\n",
    "ss_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3422.060981,
   "end_time": "2022-09-07T13:01:46.526380",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-09-07T12:04:44.465399",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
